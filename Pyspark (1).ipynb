{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066454a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad630eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ba894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0b631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/25 04:29:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/25 04:29:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b2243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|_c0|_c1| _c2|\n",
      "+---+---+----+\n",
      "|111|zzz|8000|\n",
      "|111|aaa|8888|\n",
      "|121|bbb|8000|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "empdf=spark.read.csv(\"/home/labuser/Downloads/retail-main/datasets/emp.csv\")\n",
    "\n",
    "empdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5eda2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-5-245.ap-south-1.compute.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Python Spark SQL basic example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0e209a8c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9d53d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|    CustomerName|    Segment|         City|          State|      Country|PostalCode|Market|      Region|       ProductID|       Category|Sub-Category|         ProductName|           Sales|Quantity|Discount|    Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|32298| CA-2012-124891|31/07/2012|31/07/2012|      Same Day|  RH-19495|     Rick Hansen|   Consumer|New York City|       New York|United States|     10024|    US|        East| TEC-AC-10003033|     Technology| Accessories|Plantronics CS510...|         2309.65|       7|       0|  762.1845|     933.57 |     Critical|\n",
      "|26341|  IN-2013-77878|05/02/2013|07/02/2013|  Second Class|  JR-16210|   Justin Ritter|  Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|     Oceania| FUR-CH-10003950|      Furniture|      Chairs|Novimex Executive...|           Black|3709.395|       9|       0.1|    -288.765|      923.63 |\n",
      "|25330|  IN-2013-71249|17/10/2013|18/10/2013|   First Class|  CR-12730|    Craig Reiter|   Consumer|     Brisbane|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-PH-10004664|     Technology|      Phones|   Nokia Smart Phone|  with Caller ID|5175.171|       9|       0.1|     919.971|      915.49 |\n",
      "|13524|ES-2013-1579342|28/01/2013|30/01/2013|   First Class|  KM-16375|Katherine Murray|Home Office|       Berlin|         Berlin|      Germany|      null|    EU|     Central| TEC-PH-10004583|     Technology|      Phones|Motorola Smart Phone|        Cordless| 2892.51|       5|       0.1|      -96.54|      910.16 |\n",
      "|47221|   SG-2013-4320|05/11/2013|06/11/2013|      Same Day|   RH-9495|     Rick Hansen|   Consumer|        Dakar|          Dakar|      Senegal|      null|Africa|      Africa|TEC-SHA-10000501|     Technology|     Copiers|  Sharp Wireless Fax|      High-Speed| 2832.96|       8|         0|      311.52|      903.04 |\n",
      "|22732|  IN-2013-42360|28/06/2013|01/07/2013|  Second Class|  JM-15655|     Jim Mitchum|  Corporate|       Sydney|New South Wales|    Australia|      null|  APAC|     Oceania| TEC-PH-10000030|     Technology|      Phones| Samsung Smart Phone|  with Caller ID|2862.675|       5|       0.1|     763.275|      897.35 |\n",
      "|30570|  IN-2011-81826|07/11/2011|09/11/2011|   First Class|  TS-21340|   Toby Swindell|   Consumer|      Porirua|     Wellington|  New Zealand|      null|  APAC|     Oceania| FUR-CH-10004050|      Furniture|      Chairs|Novimex Executive...|      Adjustable| 1822.08|       4|         0|      564.84|       894.77|\n",
      "|31192|  IN-2012-86369|14/04/2012|18/04/2012|Standard Class|  MB-18085|      Mick Brown|   Consumer|     Hamilton|        Waikato|  New Zealand|      null|  APAC|     Oceania| FUR-TA-10002958|      Furniture|      Tables|Chromcraft Confer...| Fully Assembled| 5244.84|       6|         0|      996.48|       878.38|\n",
      "|40155| CA-2014-135909|14/10/2014|21/10/2014|Standard Class|  JW-15220|       Jane Waco|  Corporate|   Sacramento|     California|United States|     95823|    US|        West| OFF-BI-10003527|Office Supplies|     Binders|Fellowes PB500 El...|         5083.96|       5|     0.2|  1906.485|     867.69 |          Low|\n",
      "|40936| CA-2012-116638|28/01/2012|31/01/2012|  Second Class|  JH-15985|     Joseph Holt|   Consumer|      Concord| North Carolina|United States|     28027|    US|       South| FUR-TA-10000198|      Furniture|      Tables|Chromcraft Bull-N...|        4297.644|      13|     0.4|-1862.3124|     865.74 |     Critical|\n",
      "|34577| CA-2011-102988|05/04/2011|09/04/2011|  Second Class|  GM-14695|    Greg Maxwell|  Corporate|   Alexandria|       Virginia|United States|     22304|    US|       South| OFF-SU-10002881|Office Supplies|    Supplies|Martin Yale Chadl...|         4164.05|       5|       0|    83.281|     846.54 |         High|\n",
      "|28879|  ID-2012-28402|19/04/2012|22/04/2012|   First Class|  AJ-10780|  Anthony Jacobs|  Corporate|        Kabul|          Kabul|  Afghanistan|      null|  APAC|Central Asia| FUR-TA-10001889|      Furniture|      Tables|Bevis Conference ...| Fully Assembled| 4626.15|       5|         0|      647.55|      835.57 |\n",
      "|45794|   SA-2011-1830|27/12/2011|29/12/2011|  Second Class|   MM-7260| Magdelene Morse|   Consumer|        Jizan|          Jizan| Saudi Arabia|      null|  EMEA|        EMEA|TEC-CIS-10001717|     Technology|      Phones|   Cisco Smart Phone|  with Caller ID| 2616.96|       4|         0|      1151.4|      832.41 |\n",
      "| 4132| MX-2012-130015|13/11/2012|13/11/2012|      Same Day|  VF-21715|  Vicky Freymann|Home Office|       Toledo|         Parana|       Brazil|      null| LATAM|       South| FUR-CH-10002033|      Furniture|      Chairs|Harbour Creations...|      Adjustable|  2221.8|       7|         0|      622.02|      810.25 |\n",
      "|27704|  IN-2013-73951|06/06/2013|08/06/2013|  Second Class|  PF-19120|    Peter Fuller|   Consumer|   Mudanjiang|   Heilongjiang|        China|      null|  APAC|  North Asia| OFF-AP-10003500|Office Supplies|  Appliances|KitchenAid Microwave|           White| 3701.52|      12|         0|     1036.08|      804.54 |\n",
      "|13779|ES-2014-5099955|31/07/2014|03/08/2014|  Second Class|  BP-11185|    Ben Peterman|  Corporate|        Paris|  Ile-de-France|       France|      null|    EU|     Central| OFF-AP-10000423|Office Supplies|  Appliances|Breville Refriger...|             Red|1869.588|       4|       0.1|     186.948|      801.66 |\n",
      "|36178| CA-2014-143567|03/11/2014|06/11/2014|  Second Class|  TB-21175|   Thomas Boland|  Corporate|    Henderson|       Kentucky|United States|     42420|    US|       South| TEC-AC-10004145|     Technology| Accessories|Logitech diNovo E...|         2249.91|       9|       0|  517.4793|     780.70 |     Critical|\n",
      "|12069|ES-2014-1651774|08/09/2014|14/09/2014|Standard Class|  PJ-18835|   Patrick Jones|  Corporate|        Prato|        Tuscany|        Italy|      null|    EU|       South| OFF-AP-10004512|Office Supplies|  Appliances|        Hoover Stove|             Red| 7958.58|      14|         0|     3979.08|      778.32 |\n",
      "|22096|  IN-2014-11763|31/01/2014|01/02/2014|   First Class|  JS-15685|        Jim Sink|  Corporate|   Townsville|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-CO-10000865|     Technology|     Copiers| Brother Fax Machine|      High-Speed|2565.594|       9|       0.1|      28.404|      766.93 |\n",
      "|49463|   TZ-2014-8190|05/12/2014|07/12/2014|  Second Class|   RH-9555| Ritsa Hightower|   Consumer|       Uvinza|         Kigoma|     Tanzania|      null|Africa|      Africa|OFF-KIT-10004058|Office Supplies|  Appliances|    KitchenAid Stove|           White| 3409.74|       6|         0|      818.28|      763.38 |\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesdf=spark.read.option(\"header\", \"true\").csv(\"/home/labuser/Downloads/retail-main/datasets/superstore.csv\")\n",
    "\n",
    "salesdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e383f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+\n",
      "|empno|ename| sal|\n",
      "+-----+-----+----+\n",
      "|  111|  zzz|8000|\n",
      "|  111|  aaa|8888|\n",
      "|  121|  bbb|8000|\n",
      "| NULL|  ccc|9000|\n",
      "|false|  ddd|6000|\n",
      "|  555|  eee|7000|\n",
      "|  765| null|null|\n",
      "|  666|  fff|8890|\n",
      "|  aaa| null|null|\n",
      "| True| null|null|\n",
      "| true| null|null|\n",
      "|    a|    b|   c|\n",
      "|    x| NULL|NULL|\n",
      "| 1000| null|null|\n",
      "|  222| NULL|NULL|\n",
      "+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeedf=spark.read.option(\"header\", \"true\").csv(\"/home/labuser/Downloads/retail-main/datasets/employee.csv\", inferSchema = True)\n",
    "\n",
    "employeedf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b6b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- OrderID: string (nullable = true)\n",
      " |-- OrderDate: string (nullable = true)\n",
      " |-- ShipDate: string (nullable = true)\n",
      " |-- ShipMode: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- CustomerName: string (nullable = true)\n",
      " |-- Segment: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- PostalCode: string (nullable = true)\n",
      " |-- Market: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- ProductID: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Sub-Category: string (nullable = true)\n",
      " |-- ProductName: string (nullable = true)\n",
      " |-- Sales: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- Discount: string (nullable = true)\n",
      " |-- Profit: string (nullable = true)\n",
      " |-- ShippingCost: string (nullable = true)\n",
      " |-- OrderPriority: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a7efa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: string (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- sal: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeedf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7a8bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType,IntegerType,DoubleType\n",
    "\n",
    "EmpSchema = StructType([  \n",
    "    StructField('Empno', IntegerType(), True), \n",
    "    StructField('Empname', StringType(), True),    \n",
    "     StructField('salary', DoubleType(), True) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8f353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "employeedf=spark.read.option(\"header\",\"true\").schema(EmpSchema).csv(\"/home/labuser/Downloads/retail-main/datasets/employee.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71db74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Empno: integer (nullable = true)\n",
      " |-- Empname: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeedf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f2ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+\n",
      "|Empno|Empname|salary|\n",
      "+-----+-------+------+\n",
      "|  111|    zzz|8000.0|\n",
      "|  111|    aaa|8888.0|\n",
      "|  121|    bbb|8000.0|\n",
      "| null|    ccc|9000.0|\n",
      "| null|    ddd|6000.0|\n",
      "|  555|    eee|7000.0|\n",
      "|  765|   null|  null|\n",
      "|  666|    fff|8890.0|\n",
      "| null|   null|  null|\n",
      "| null|   null|  null|\n",
      "| null|   null|  null|\n",
      "| null|      b|  null|\n",
      "| null|   NULL|  null|\n",
      "| 1000|   null|  null|\n",
      "|  222|   NULL|  null|\n",
      "+-----+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/25 04:29:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: empno, ename, sal\n",
      " Schema: Empno, Empname, salary\n",
      "Expected: Empname but found: ename\n",
      "CSV file: file:///home/labuser/Downloads/retail-main/datasets/employee.csv\n"
     ]
    }
   ],
   "source": [
    "employeedf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92014431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+\n",
      "|Empno|Empname|salary|\n",
      "+-----+-------+------+\n",
      "|  111|    zzz|8000.0|\n",
      "|  111|    aaa|8888.0|\n",
      "|  121|    bbb|8000.0|\n",
      "|  555|    eee|7000.0|\n",
      "|  666|    fff|8890.0|\n",
      "+-----+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/25 04:29:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: empno, ename, sal\n",
      " Schema: Empno, Empname, salary\n",
      "Expected: Empname but found: ename\n",
      "CSV file: file:///home/labuser/Downloads/retail-main/datasets/employee.csv\n"
     ]
    }
   ],
   "source": [
    "employeedf=spark.read.option(\"header\",\"true\").option(\"mode\", \"dropmalformed\").schema(EmpSchema).csv(\"/home/labuser/Downloads/retail-main/datasets/employee.csv\")\n",
    "employeedf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48b32488",
   "metadata": {},
   "outputs": [],
   "source": [
    "employeedf=spark.read.option(\"header\",\"true\").option(\"mode\",\"failfast\").schema(EmpSchema).csv(\"/home/labuser/Downloads/retail-main/datasets/employee.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50abb3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/25 04:29:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: empno, ename, sal\n",
      " Schema: Empno, Empname, salary\n",
      "Expected: Empname but found: ename\n",
      "CSV file: file:///home/labuser/Downloads/retail-main/datasets/employee.csv\n",
      "23/09/25 04:29:23 ERROR Executor: Exception in task 0.0 in stage 9.0 (TID 9)\n",
      "org.apache.spark.SparkException: [MALFORMED_RECORD_IN_PARSING] Malformed records are detected in record parsing: [null,ccc,9000.0].\n",
      "Parse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1764)\n",
      "\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:125)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"NULL\"\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:365)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)\n",
      "\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)\n",
      "\t... 24 more\n",
      "Caused by: java.lang.NumberFormatException: For input string: \"NULL\"\n",
      "\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n",
      "\tat java.lang.Integer.parseInt(Integer.java:580)\n",
      "\tat java.lang.Integer.parseInt(Integer.java:615)\n",
      "\tat scala.collection.immutable.StringLike.toInt(StringLike.scala:304)\n",
      "\tat scala.collection.immutable.StringLike.toInt$(StringLike.scala:304)\n",
      "\tat scala.collection.immutable.StringOps.toInt(StringOps.scala:33)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6(UnivocityParser.scala:189)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6$adapted(UnivocityParser.scala:189)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$5(UnivocityParser.scala:189)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)\n",
      "\t... 27 more\n",
      "23/09/25 04:29:23 WARN TaskSetManager: Lost task 0.0 in stage 9.0 (TID 9) (ip-172-31-5-245.ap-south-1.compute.internal executor driver): org.apache.spark.SparkException: [MALFORMED_RECORD_IN_PARSING] Malformed records are detected in record parsing: [null,ccc,9000.0].\n",
      "Parse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1764)\n",
      "\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:125)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"NULL\"\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:365)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)\n",
      "\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)\n",
      "\t... 24 more\n",
      "Caused by: java.lang.NumberFormatException: For input string: \"NULL\"\n",
      "\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n",
      "\tat java.lang.Integer.parseInt(Integer.java:580)\n",
      "\tat java.lang.Integer.parseInt(Integer.java:615)\n",
      "\tat scala.collection.immutable.StringLike.toInt(StringLike.scala:304)\n",
      "\tat scala.collection.immutable.StringLike.toInt$(StringLike.scala:304)\n",
      "\tat scala.collection.immutable.StringOps.toInt(StringOps.scala:33)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6(UnivocityParser.scala:189)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6$adapted(UnivocityParser.scala:189)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$5(UnivocityParser.scala:189)\n",
      "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)\n",
      "\t... 27 more\n",
      "\n",
      "23/09/25 04:29:23 ERROR TaskSetManager: Task 0 in stage 9.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o87.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 9) (ip-172-31-5-245.ap-south-1.compute.internal executor driver): org.apache.spark.SparkException: [MALFORMED_RECORD_IN_PARSING] Malformed records are detected in record parsing: [null,ccc,9000.0].\nParse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1764)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:69)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:125)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"NULL\"\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:365)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)\n\t... 24 more\nCaused by: java.lang.NumberFormatException: For input string: \"NULL\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Integer.parseInt(Integer.java:580)\n\tat java.lang.Integer.parseInt(Integer.java:615)\n\tat scala.collection.immutable.StringLike.toInt(StringLike.scala:304)\n\tat scala.collection.immutable.StringLike.toInt$(StringLike.scala:304)\n\tat scala.collection.immutable.StringOps.toInt(StringOps.scala:33)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6$adapted(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$5(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)\n\t... 27 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3382)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:284)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:323)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: [MALFORMED_RECORD_IN_PARSING] Malformed records are detected in record parsing: [null,ccc,9000.0].\nParse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1764)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:69)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:125)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"NULL\"\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:365)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)\n\t... 24 more\nCaused by: java.lang.NumberFormatException: For input string: \"NULL\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Integer.parseInt(Integer.java:580)\n\tat java.lang.Integer.parseInt(Integer.java:615)\n\tat scala.collection.immutable.StringLike.toInt(StringLike.scala:304)\n\tat scala.collection.immutable.StringLike.toInt$(StringLike.scala:304)\n\tat scala.collection.immutable.StringOps.toInt(StringOps.scala:33)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6$adapted(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$5(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)\n\t... 27 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m employeedf\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/sql/dataframe.py:899\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    894\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    895\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 899\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mshowString(n, \u001b[38;5;241m20\u001b[39m, vertical))\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o87.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 9) (ip-172-31-5-245.ap-south-1.compute.internal executor driver): org.apache.spark.SparkException: [MALFORMED_RECORD_IN_PARSING] Malformed records are detected in record parsing: [null,ccc,9000.0].\nParse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1764)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:69)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:125)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"NULL\"\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:365)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)\n\t... 24 more\nCaused by: java.lang.NumberFormatException: For input string: \"NULL\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Integer.parseInt(Integer.java:580)\n\tat java.lang.Integer.parseInt(Integer.java:615)\n\tat scala.collection.immutable.StringLike.toInt(StringLike.scala:304)\n\tat scala.collection.immutable.StringLike.toInt$(StringLike.scala:304)\n\tat scala.collection.immutable.StringOps.toInt(StringOps.scala:33)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6$adapted(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$5(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)\n\t... 27 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3161)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3382)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:284)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:323)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: [MALFORMED_RECORD_IN_PARSING] Malformed records are detected in record parsing: [null,ccc,9000.0].\nParse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1764)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:69)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:456)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:125)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"NULL\"\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:365)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:307)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:452)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:60)\n\t... 24 more\nCaused by: java.lang.NumberFormatException: For input string: \"NULL\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Integer.parseInt(Integer.java:580)\n\tat java.lang.Integer.parseInt(Integer.java:615)\n\tat scala.collection.immutable.StringLike.toInt(StringLike.scala:304)\n\tat scala.collection.immutable.StringLike.toInt$(StringLike.scala:304)\n\tat scala.collection.immutable.StringOps.toInt(StringOps.scala:33)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$6$adapted(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:291)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$5(UnivocityParser.scala:189)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.org$apache$spark$sql$catalyst$csv$UnivocityParser$$convert(UnivocityParser.scala:346)\n\t... 27 more\n"
     ]
    }
   ],
   "source": [
    "employeedf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f9a7bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ID='32298', OrderID='CA-2012-124891', OrderDate='31/07/2012', ShipDate='31/07/2012', ShipMode='Same Day', CustomerID='RH-19495', CustomerName='Rick Hansen', Segment='Consumer', City='New York City', State='New York', Country='United States', PostalCode='10024', Market='US', Region='East', ProductID='TEC-AC-10003033', Category='Technology', Sub-Category='Accessories', ProductName='Plantronics CS510 - Over-the-Head monaural Wireless Headset System', Sales='2309.65', Quantity='7', Discount='0', Profit='762.1845', ShippingCost=' 933.57 ', OrderPriority='Critical')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c97a2ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51290"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb4c5c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c4749fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+----------+----------+------------+----------+-------------+---------+-------------+---------------+-------------+----------+------+-------+---------------+----------+------------+--------------------+-------+--------+--------+--------+------------+-------------+\n",
      "|   ID|       OrderID| OrderDate|  ShipDate|    ShipMode|CustomerID| CustomerName|  Segment|         City|          State|      Country|PostalCode|Market| Region|      ProductID|  Category|Sub-Category|         ProductName|  Sales|Quantity|Discount|  Profit|ShippingCost|OrderPriority|\n",
      "+-----+--------------+----------+----------+------------+----------+-------------+---------+-------------+---------------+-------------+----------+------+-------+---------------+----------+------------+--------------------+-------+--------+--------+--------+------------+-------------+\n",
      "|32298|CA-2012-124891|31/07/2012|31/07/2012|    Same Day|  RH-19495|  Rick Hansen| Consumer|New York City|       New York|United States|     10024|    US|   East|TEC-AC-10003033|Technology| Accessories|Plantronics CS510...|2309.65|       7|       0|762.1845|     933.57 |     Critical|\n",
      "|26341| IN-2013-77878|05/02/2013|07/02/2013|Second Class|  JR-16210|Justin Ritter|Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|Oceania|FUR-CH-10003950| Furniture|      Chairs|Novimex Executive...|  Black|3709.395|       9|     0.1|    -288.765|      923.63 |\n",
      "+-----+--------------+----------+----------+------------+----------+-------------+---------+-------------+---------------+-------------+----------+------+-------+---------------+----------+------------+--------------------+-------+--------+--------+--------+------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesdf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5f0bc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ID='32298', OrderID='CA-2012-124891', OrderDate='31/07/2012', ShipDate='31/07/2012', ShipMode='Same Day', CustomerID='RH-19495', CustomerName='Rick Hansen', Segment='Consumer', City='New York City', State='New York', Country='United States', PostalCode='10024', Market='US', Region='East', ProductID='TEC-AC-10003033', Category='Technology', Sub-Category='Accessories', ProductName='Plantronics CS510 - Over-the-Head monaural Wireless Headset System', Sales='2309.65', Quantity='7', Discount='0', Profit='762.1845', ShippingCost=' 933.57 ', OrderPriority='Critical')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0846e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|      country|          state|\n",
      "+-------------+---------------+\n",
      "|United States|       New York|\n",
      "|    Australia|New South Wales|\n",
      "|    Australia|     Queensland|\n",
      "|      Germany|         Berlin|\n",
      "|      Senegal|          Dakar|\n",
      "|    Australia|New South Wales|\n",
      "|  New Zealand|     Wellington|\n",
      "|  New Zealand|        Waikato|\n",
      "|United States|     California|\n",
      "|United States| North Carolina|\n",
      "|United States|       Virginia|\n",
      "|  Afghanistan|          Kabul|\n",
      "| Saudi Arabia|          Jizan|\n",
      "|       Brazil|         Parana|\n",
      "|        China|   Heilongjiang|\n",
      "|       France|  Ile-de-France|\n",
      "|United States|       Kentucky|\n",
      "|        Italy|        Tuscany|\n",
      "|    Australia|     Queensland|\n",
      "|     Tanzania|         Kigoma|\n",
      "+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesdf.select(\"country\", \"state\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "131cd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1555"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.select(\"country\", \"state\").filter(\"country= 'India'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0f6f73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 20:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|country|            state|\n",
      "+-------+-----------------+\n",
      "|  India|      Maharashtra|\n",
      "|  India|    Uttar Pradesh|\n",
      "|  India|      Uttarakhand|\n",
      "|  India|           Kerala|\n",
      "|  India|     Chhattisgarh|\n",
      "|  India|       Tamil Nadu|\n",
      "|  India|            Assam|\n",
      "|  India|        Telangana|\n",
      "|  India|       Chandigarh|\n",
      "|  India|Jammu and Kashmir|\n",
      "|  India|          Manipur|\n",
      "|  India|           Odisha|\n",
      "|  India|   Andhra Pradesh|\n",
      "|  India|          Haryana|\n",
      "|  India|          Tripura|\n",
      "|  India|            Bihar|\n",
      "|  India|        Rajasthan|\n",
      "|  India|           Punjab|\n",
      "|  India|          Gujarat|\n",
      "|  India|      West Bengal|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesdf.select(\"country\", \"state\").filter(\"country= 'India'\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0d4bed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indiadf=salesdf.select(\"country\", \"state\", \"category\", \"profit\").filter(\"country= 'India'\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36796c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(indiadf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7584e6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country: string, state: string, category: string, profit: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indiadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d29e617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 23:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indiadf.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f058d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99944192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|    CustomerName|    Segment|         City|          State|      Country|PostalCode|Market|      Region|       ProductID|       Category|Sub-Category|         ProductName|           Sales|Quantity|Discount|    Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|32298| CA-2012-124891|31/07/2012|31/07/2012|      Same Day|  RH-19495|     Rick Hansen|   Consumer|New York City|       New York|United States|     10024|    US|        East| TEC-AC-10003033|     Technology| Accessories|Plantronics CS510...|         2309.65|       7|       0|  762.1845|     933.57 |     Critical|\n",
      "|26341|  IN-2013-77878|05/02/2013|07/02/2013|  Second Class|  JR-16210|   Justin Ritter|  Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|     Oceania| FUR-CH-10003950|      Furniture|      Chairs|Novimex Executive...|           Black|3709.395|       9|       0.1|    -288.765|      923.63 |\n",
      "|25330|  IN-2013-71249|17/10/2013|18/10/2013|   First Class|  CR-12730|    Craig Reiter|   Consumer|     Brisbane|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-PH-10004664|     Technology|      Phones|   Nokia Smart Phone|  with Caller ID|5175.171|       9|       0.1|     919.971|      915.49 |\n",
      "|13524|ES-2013-1579342|28/01/2013|30/01/2013|   First Class|  KM-16375|Katherine Murray|Home Office|       Berlin|         Berlin|      Germany|      null|    EU|     Central| TEC-PH-10004583|     Technology|      Phones|Motorola Smart Phone|        Cordless| 2892.51|       5|       0.1|      -96.54|      910.16 |\n",
      "|47221|   SG-2013-4320|05/11/2013|06/11/2013|      Same Day|   RH-9495|     Rick Hansen|   Consumer|        Dakar|          Dakar|      Senegal|      null|Africa|      Africa|TEC-SHA-10000501|     Technology|     Copiers|  Sharp Wireless Fax|      High-Speed| 2832.96|       8|         0|      311.52|      903.04 |\n",
      "|22732|  IN-2013-42360|28/06/2013|01/07/2013|  Second Class|  JM-15655|     Jim Mitchum|  Corporate|       Sydney|New South Wales|    Australia|      null|  APAC|     Oceania| TEC-PH-10000030|     Technology|      Phones| Samsung Smart Phone|  with Caller ID|2862.675|       5|       0.1|     763.275|      897.35 |\n",
      "|30570|  IN-2011-81826|07/11/2011|09/11/2011|   First Class|  TS-21340|   Toby Swindell|   Consumer|      Porirua|     Wellington|  New Zealand|      null|  APAC|     Oceania| FUR-CH-10004050|      Furniture|      Chairs|Novimex Executive...|      Adjustable| 1822.08|       4|         0|      564.84|       894.77|\n",
      "|31192|  IN-2012-86369|14/04/2012|18/04/2012|Standard Class|  MB-18085|      Mick Brown|   Consumer|     Hamilton|        Waikato|  New Zealand|      null|  APAC|     Oceania| FUR-TA-10002958|      Furniture|      Tables|Chromcraft Confer...| Fully Assembled| 5244.84|       6|         0|      996.48|       878.38|\n",
      "|40155| CA-2014-135909|14/10/2014|21/10/2014|Standard Class|  JW-15220|       Jane Waco|  Corporate|   Sacramento|     California|United States|     95823|    US|        West| OFF-BI-10003527|Office Supplies|     Binders|Fellowes PB500 El...|         5083.96|       5|     0.2|  1906.485|     867.69 |          Low|\n",
      "|40936| CA-2012-116638|28/01/2012|31/01/2012|  Second Class|  JH-15985|     Joseph Holt|   Consumer|      Concord| North Carolina|United States|     28027|    US|       South| FUR-TA-10000198|      Furniture|      Tables|Chromcraft Bull-N...|        4297.644|      13|     0.4|-1862.3124|     865.74 |     Critical|\n",
      "|34577| CA-2011-102988|05/04/2011|09/04/2011|  Second Class|  GM-14695|    Greg Maxwell|  Corporate|   Alexandria|       Virginia|United States|     22304|    US|       South| OFF-SU-10002881|Office Supplies|    Supplies|Martin Yale Chadl...|         4164.05|       5|       0|    83.281|     846.54 |         High|\n",
      "|28879|  ID-2012-28402|19/04/2012|22/04/2012|   First Class|  AJ-10780|  Anthony Jacobs|  Corporate|        Kabul|          Kabul|  Afghanistan|      null|  APAC|Central Asia| FUR-TA-10001889|      Furniture|      Tables|Bevis Conference ...| Fully Assembled| 4626.15|       5|         0|      647.55|      835.57 |\n",
      "|45794|   SA-2011-1830|27/12/2011|29/12/2011|  Second Class|   MM-7260| Magdelene Morse|   Consumer|        Jizan|          Jizan| Saudi Arabia|      null|  EMEA|        EMEA|TEC-CIS-10001717|     Technology|      Phones|   Cisco Smart Phone|  with Caller ID| 2616.96|       4|         0|      1151.4|      832.41 |\n",
      "| 4132| MX-2012-130015|13/11/2012|13/11/2012|      Same Day|  VF-21715|  Vicky Freymann|Home Office|       Toledo|         Parana|       Brazil|      null| LATAM|       South| FUR-CH-10002033|      Furniture|      Chairs|Harbour Creations...|      Adjustable|  2221.8|       7|         0|      622.02|      810.25 |\n",
      "|27704|  IN-2013-73951|06/06/2013|08/06/2013|  Second Class|  PF-19120|    Peter Fuller|   Consumer|   Mudanjiang|   Heilongjiang|        China|      null|  APAC|  North Asia| OFF-AP-10003500|Office Supplies|  Appliances|KitchenAid Microwave|           White| 3701.52|      12|         0|     1036.08|      804.54 |\n",
      "|13779|ES-2014-5099955|31/07/2014|03/08/2014|  Second Class|  BP-11185|    Ben Peterman|  Corporate|        Paris|  Ile-de-France|       France|      null|    EU|     Central| OFF-AP-10000423|Office Supplies|  Appliances|Breville Refriger...|             Red|1869.588|       4|       0.1|     186.948|      801.66 |\n",
      "|36178| CA-2014-143567|03/11/2014|06/11/2014|  Second Class|  TB-21175|   Thomas Boland|  Corporate|    Henderson|       Kentucky|United States|     42420|    US|       South| TEC-AC-10004145|     Technology| Accessories|Logitech diNovo E...|         2249.91|       9|       0|  517.4793|     780.70 |     Critical|\n",
      "|12069|ES-2014-1651774|08/09/2014|14/09/2014|Standard Class|  PJ-18835|   Patrick Jones|  Corporate|        Prato|        Tuscany|        Italy|      null|    EU|       South| OFF-AP-10004512|Office Supplies|  Appliances|        Hoover Stove|             Red| 7958.58|      14|         0|     3979.08|      778.32 |\n",
      "|22096|  IN-2014-11763|31/01/2014|01/02/2014|   First Class|  JS-15685|        Jim Sink|  Corporate|   Townsville|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-CO-10000865|     Technology|     Copiers| Brother Fax Machine|      High-Speed|2565.594|       9|       0.1|      28.404|      766.93 |\n",
      "|49463|   TZ-2014-8190|05/12/2014|07/12/2014|  Second Class|   RH-9555| Ritsa Hightower|   Consumer|       Uvinza|         Kigoma|     Tanzania|      null|Africa|      Africa|OFF-KIT-10004058|Office Supplies|  Appliances|    KitchenAid Stove|           White| 3409.74|       6|         0|      818.28|      763.38 |\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salesdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "268bd82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indiadf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4c560b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ip-172-31-5-245.ap-south-1.compute.internal:4041'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.uiWebUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83884689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 33:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indiadf.write.format(\"json\").save(\"/home/labuser/Downloads/sparkout/sales_india\", mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c439d402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b025ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51290"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71c555e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/home/labuser/Downloads/retail-main/output/sales_repart8 already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m salesdf\u001b[38;5;241m.\u001b[39mrepartition(\u001b[38;5;241m8\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39morc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/labuser/Downloads/retail-main/output/sales_repart8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/sql/readwriter.py:1862\u001b[0m, in \u001b[0;36mDataFrameWriter.orc\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1862\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39morc(path)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/home/labuser/Downloads/retail-main/output/sales_repart8 already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "salesdf.repartition(8).write.orc(\"/home/labuser/Downloads/retail-main/output/sales_repart8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de644e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/home/labuser/Downloads/retail-main/output/sales_repart already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m salesdf\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mparquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/labuser/Downloads/retail-main/output/sales_repart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/sql/readwriter.py:1656\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39mparquet(path)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/home/labuser/Downloads/retail-main/output/sales_repart already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "salesdf.write.parquet(\"/home/labuser/Downloads/retail-main/output/sales_repart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2c42372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sales_parquet = spark.read.format(\"parquet\").load(\"/home/labuser/Downloads/retail-main/output/sales_repart/part-00000-7f105830-a159-4085-8e29-8e5324c0ec44-c000.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afa2bd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34577"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_parquet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a05c1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_orc = spark.read.format(\"orc\").load(\"/home/labuser/Downloads/retail-main/output/sales_repart8/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfe1f0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_orc.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a420d842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+------------------+-----------+--------------+--------------------+---------------+----------+------+--------------+----------------+---------------+------------+--------------------+-----------+--------+--------+--------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|      CustomerName|    Segment|          City|               State|        Country|PostalCode|Market|        Region|       ProductID|       Category|Sub-Category|         ProductName|      Sales|Quantity|Discount|  Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+------------------+-----------+--------------+--------------------+---------------+----------+------+--------------+----------------+---------------+------------+--------------------+-----------+--------+--------+--------+------------+-------------+\n",
      "|40943| US-2014-107979|09/06/2014|14/06/2014|Standard Class|  FO-14305|       Frank Olsen|   Consumer|      Glendale|             Arizona|  United States|     85301|    US|          West| OFF-BI-10000778|Office Supplies|     Binders|GBC VeloBinder El...|     72.588|       2|     0.7| -48.392|       5.01 |       Medium|\n",
      "|29022|  ID-2013-39182|30/01/2013|04/02/2013|Standard Class|  CD-12280|  Christina DeMoss|   Consumer|        Yangon|              Yangon|Myanmar (Burma)|      null|  APAC|Southeast Asia| OFF-ST-10000016|Office Supplies|     Storage|       Eldon Folders|       Blue| 42.2802|       3|    0.17|      7.0902|        3.72 |\n",
      "|27536|  IN-2014-27303|30/01/2014|03/02/2014|Standard Class|  RA-19885|      Ruben Ausman|  Corporate|       Beijing|             Beijing|          China|      null|  APAC|    North Asia| FUR-FU-10000921|      Furniture| Furnishings|  Advantus Door Stop|  Erganomic|   174.6|       4|       0|        15.6|       30.15 |\n",
      "|18707|ES-2014-5296123|30/06/2014|07/07/2014|Standard Class|  AC-10615|         Ann Chong|  Corporate|         Paris|       Ile-de-France|         France|      null|    EU|       Central| OFF-AR-10000219|Office Supplies|         Art|Sanford Highlighters|       Blue|  110.25|       7|       0|       11.97|        9.15 |\n",
      "|24523|  IN-2013-72145|17/05/2013|24/05/2013|Standard Class|  MG-17650| Matthew Grinstein|Home Office|     Singapore|           Singapore|      Singapore|      null|  APAC|Southeast Asia| OFF-PA-10003938|Office Supplies|       Paper|Eaton Cards & Env...|    Premium|  361.44|       8|       0|       79.44|       27.83 |\n",
      "| 1625| MX-2011-165106|04/11/2011|07/11/2011|  Second Class|  JL-15835|          John Lee|   Consumer|     Soyapango|        San Salvador|    El Salvador|      null| LATAM|       Central| FUR-FU-10003384|      Furniture| Furnishings|Advantus Photo Frame|   Duo Pack|  141.44|       4|       0|       67.84|       19.47 |\n",
      "|15506|ES-2014-2920154|20/02/2014|24/02/2014|Standard Class|  RD-19660|    Robert Dilbeck|Home Office|        Munich|             Bavaria|        Germany|      null|    EU|       Central| FUR-FU-10004608|      Furniture| Furnishings|  Advantus Door Stop|  Erganomic|  130.95|       3|       0|       40.59|       17.58 |\n",
      "|11031|ES-2014-5297510|29/12/2014|05/01/2015|Standard Class|  BM-11785|       Bryan Mills|   Consumer|       Gosport|             England| United Kingdom|      null|    EU|         North| OFF-ST-10000300|Office Supplies|     Storage|       Eldon Folders| Wire Frame|    64.2|       4|       0|        6.36|        7.41 |\n",
      "|36361| CA-2014-122196|23/09/2014|25/09/2014|   First Class|  CA-12265|Christina Anderson|   Consumer|    Wilmington|            Delaware|  United States|     19805|    US|          East| TEC-PH-10004977|     Technology|      Phones|         GE 30524EE4|     391.98|       2|       0|113.6742|     155.34 |     Critical|\n",
      "|14133|ES-2013-2313397|12/10/2013|13/10/2013|   First Class|  LR-16915|      Lena Radford|   Consumer|        Madrid|              Madrid|          Spain|      null|    EU|         South| OFF-AR-10000715|Office Supplies|         Art|      Boston Markers|       Blue|  158.22|       6|       0|        64.8|       43.98 |\n",
      "|11950|ES-2014-2332714|16/08/2014|19/08/2014|  Second Class|  CC-12610|     Corey Catlett|  Corporate|Recklinghausen|North Rhine-Westp...|        Germany|      null|    EU|       Central| TEC-PH-10000879|     Technology|      Phones|   Cisco Smart Phone|  Full Size| 1954.17|       3|       0|      429.84|       20.70 |\n",
      "| 7456| MX-2012-122756|31/12/2012|05/01/2013|Standard Class|  DJ-13420|         Denny Joy|  Corporate|  Villahermosa|             Tabasco|         Mexico|      null| LATAM|         North| FUR-BO-10002235|      Furniture|   Bookcases|Bush 3-Shelf Cabinet|       Pine| 154.368|       2|     0.2|      30.848|       25.24 |\n",
      "|37088| CA-2014-140186|30/09/2014|03/10/2014|   First Class|  PG-18820|   Patrick Gardner|   Consumer|   Bakersfield|          California|  United States|     93309|    US|          West| FUR-CH-10002961|      Furniture|      Chairs|  Leather Task Chair|      Black|  72.784|       1|     0.2|           0|       17.92 |\n",
      "|36527| CA-2014-124436|20/03/2014|23/03/2014|  Second Class|  SA-20830|      Sue Ann Reed|   Consumer|        Fresno|          California|  United States|     93727|    US|          West| FUR-TA-10001095|      Furniture|      Tables|Chromcraft Round ...|     697.16|       5|     0.2|  8.7145|      54.31 |         High|\n",
      "|39899| US-2011-133949|31/12/2011|31/12/2011|      Same Day|  JL-15175|      James Lanier|Home Office|          Reno|              Nevada|  United States|     89502|    US|          West| TEC-PH-10004908|     Technology|      Phones|Panasonic KX TS32...|    475.944|       7|     0.2|  59.493|     128.31 |       Medium|\n",
      "|29653|  ID-2014-33330|25/06/2014|29/06/2014|  Second Class|  GM-14500|      Gene McClure|   Consumer|       Bangkok|             Bangkok|       Thailand|      null|  APAC|Southeast Asia| OFF-SU-10001869|Office Supplies|    Supplies|   Stiletto Scissors|      Steel| 60.9765|       5|    0.47|    -51.8235|        8.56 |\n",
      "|42931|   ZI-2012-4330|04/06/2012|07/06/2012|  Second Class|   DN-3690|      Duane Noonan|   Consumer|   Chitungwiza|              Harare|       Zimbabwe|      null|Africa|        Africa|OFF-EAT-10002068|Office Supplies|       Paper|    Eaton Note Cards|    Premium|  31.896|       4|     0.7|     -74.424|        4.42 |\n",
      "|12934|ES-2011-5338028|28/12/2011|01/01/2012|  Second Class|  MH-18115|    Mick Hernandez|Home Office|         Turin|            Piedmont|          Italy|      null|    EU|         South| OFF-BI-10002511|Office Supplies|     Binders|  Avery 3-Hole Punch|      Clear|  136.65|       5|       0|        17.7|       15.30 |\n",
      "|30702|  IN-2014-82736|11/07/2014|15/07/2014|Standard Class|  EB-13705|        Ed Braxton|  Corporate|      Hamilton|             Waikato|    New Zealand|      null|  APAC|       Oceania| TEC-MA-10000858|     Technology|    Machines|   Panasonic Printer|      White|   529.8|       2|       0|       68.82|        39.87|\n",
      "|48870|   PL-2014-6080|14/11/2014|18/11/2014|Standard Class|   FM-4290|      Frank Merwin|Home Office|         Radom|             Masovia|         Poland|      null|  EMEA|          EMEA|FUR-OFF-10004495|      Furniture|      Chairs|Office Star Swive...|      Black|  171.51|       1|       0|       58.29|       17.65 |\n",
      "+-----+---------------+----------+----------+--------------+----------+------------------+-----------+--------------+--------------------+---------------+----------+------+--------------+----------------+---------------+------------+--------------------+-----------+--------+--------+--------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_orc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b01d713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_coalescedf=sales_orc.coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0faad171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+------------------+-----------+--------------+--------------------+---------------+----------+------+--------------+----------------+---------------+------------+--------------------+-----------+--------+--------+--------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|      CustomerName|    Segment|          City|               State|        Country|PostalCode|Market|        Region|       ProductID|       Category|Sub-Category|         ProductName|      Sales|Quantity|Discount|  Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+------------------+-----------+--------------+--------------------+---------------+----------+------+--------------+----------------+---------------+------------+--------------------+-----------+--------+--------+--------+------------+-------------+\n",
      "|40943| US-2014-107979|09/06/2014|14/06/2014|Standard Class|  FO-14305|       Frank Olsen|   Consumer|      Glendale|             Arizona|  United States|     85301|    US|          West| OFF-BI-10000778|Office Supplies|     Binders|GBC VeloBinder El...|     72.588|       2|     0.7| -48.392|       5.01 |       Medium|\n",
      "|29022|  ID-2013-39182|30/01/2013|04/02/2013|Standard Class|  CD-12280|  Christina DeMoss|   Consumer|        Yangon|              Yangon|Myanmar (Burma)|      null|  APAC|Southeast Asia| OFF-ST-10000016|Office Supplies|     Storage|       Eldon Folders|       Blue| 42.2802|       3|    0.17|      7.0902|        3.72 |\n",
      "|27536|  IN-2014-27303|30/01/2014|03/02/2014|Standard Class|  RA-19885|      Ruben Ausman|  Corporate|       Beijing|             Beijing|          China|      null|  APAC|    North Asia| FUR-FU-10000921|      Furniture| Furnishings|  Advantus Door Stop|  Erganomic|   174.6|       4|       0|        15.6|       30.15 |\n",
      "|18707|ES-2014-5296123|30/06/2014|07/07/2014|Standard Class|  AC-10615|         Ann Chong|  Corporate|         Paris|       Ile-de-France|         France|      null|    EU|       Central| OFF-AR-10000219|Office Supplies|         Art|Sanford Highlighters|       Blue|  110.25|       7|       0|       11.97|        9.15 |\n",
      "|24523|  IN-2013-72145|17/05/2013|24/05/2013|Standard Class|  MG-17650| Matthew Grinstein|Home Office|     Singapore|           Singapore|      Singapore|      null|  APAC|Southeast Asia| OFF-PA-10003938|Office Supplies|       Paper|Eaton Cards & Env...|    Premium|  361.44|       8|       0|       79.44|       27.83 |\n",
      "| 1625| MX-2011-165106|04/11/2011|07/11/2011|  Second Class|  JL-15835|          John Lee|   Consumer|     Soyapango|        San Salvador|    El Salvador|      null| LATAM|       Central| FUR-FU-10003384|      Furniture| Furnishings|Advantus Photo Frame|   Duo Pack|  141.44|       4|       0|       67.84|       19.47 |\n",
      "|15506|ES-2014-2920154|20/02/2014|24/02/2014|Standard Class|  RD-19660|    Robert Dilbeck|Home Office|        Munich|             Bavaria|        Germany|      null|    EU|       Central| FUR-FU-10004608|      Furniture| Furnishings|  Advantus Door Stop|  Erganomic|  130.95|       3|       0|       40.59|       17.58 |\n",
      "|11031|ES-2014-5297510|29/12/2014|05/01/2015|Standard Class|  BM-11785|       Bryan Mills|   Consumer|       Gosport|             England| United Kingdom|      null|    EU|         North| OFF-ST-10000300|Office Supplies|     Storage|       Eldon Folders| Wire Frame|    64.2|       4|       0|        6.36|        7.41 |\n",
      "|36361| CA-2014-122196|23/09/2014|25/09/2014|   First Class|  CA-12265|Christina Anderson|   Consumer|    Wilmington|            Delaware|  United States|     19805|    US|          East| TEC-PH-10004977|     Technology|      Phones|         GE 30524EE4|     391.98|       2|       0|113.6742|     155.34 |     Critical|\n",
      "|14133|ES-2013-2313397|12/10/2013|13/10/2013|   First Class|  LR-16915|      Lena Radford|   Consumer|        Madrid|              Madrid|          Spain|      null|    EU|         South| OFF-AR-10000715|Office Supplies|         Art|      Boston Markers|       Blue|  158.22|       6|       0|        64.8|       43.98 |\n",
      "|11950|ES-2014-2332714|16/08/2014|19/08/2014|  Second Class|  CC-12610|     Corey Catlett|  Corporate|Recklinghausen|North Rhine-Westp...|        Germany|      null|    EU|       Central| TEC-PH-10000879|     Technology|      Phones|   Cisco Smart Phone|  Full Size| 1954.17|       3|       0|      429.84|       20.70 |\n",
      "| 7456| MX-2012-122756|31/12/2012|05/01/2013|Standard Class|  DJ-13420|         Denny Joy|  Corporate|  Villahermosa|             Tabasco|         Mexico|      null| LATAM|         North| FUR-BO-10002235|      Furniture|   Bookcases|Bush 3-Shelf Cabinet|       Pine| 154.368|       2|     0.2|      30.848|       25.24 |\n",
      "|37088| CA-2014-140186|30/09/2014|03/10/2014|   First Class|  PG-18820|   Patrick Gardner|   Consumer|   Bakersfield|          California|  United States|     93309|    US|          West| FUR-CH-10002961|      Furniture|      Chairs|  Leather Task Chair|      Black|  72.784|       1|     0.2|           0|       17.92 |\n",
      "|36527| CA-2014-124436|20/03/2014|23/03/2014|  Second Class|  SA-20830|      Sue Ann Reed|   Consumer|        Fresno|          California|  United States|     93727|    US|          West| FUR-TA-10001095|      Furniture|      Tables|Chromcraft Round ...|     697.16|       5|     0.2|  8.7145|      54.31 |         High|\n",
      "|39899| US-2011-133949|31/12/2011|31/12/2011|      Same Day|  JL-15175|      James Lanier|Home Office|          Reno|              Nevada|  United States|     89502|    US|          West| TEC-PH-10004908|     Technology|      Phones|Panasonic KX TS32...|    475.944|       7|     0.2|  59.493|     128.31 |       Medium|\n",
      "|29653|  ID-2014-33330|25/06/2014|29/06/2014|  Second Class|  GM-14500|      Gene McClure|   Consumer|       Bangkok|             Bangkok|       Thailand|      null|  APAC|Southeast Asia| OFF-SU-10001869|Office Supplies|    Supplies|   Stiletto Scissors|      Steel| 60.9765|       5|    0.47|    -51.8235|        8.56 |\n",
      "|42931|   ZI-2012-4330|04/06/2012|07/06/2012|  Second Class|   DN-3690|      Duane Noonan|   Consumer|   Chitungwiza|              Harare|       Zimbabwe|      null|Africa|        Africa|OFF-EAT-10002068|Office Supplies|       Paper|    Eaton Note Cards|    Premium|  31.896|       4|     0.7|     -74.424|        4.42 |\n",
      "|12934|ES-2011-5338028|28/12/2011|01/01/2012|  Second Class|  MH-18115|    Mick Hernandez|Home Office|         Turin|            Piedmont|          Italy|      null|    EU|         South| OFF-BI-10002511|Office Supplies|     Binders|  Avery 3-Hole Punch|      Clear|  136.65|       5|       0|        17.7|       15.30 |\n",
      "|30702|  IN-2014-82736|11/07/2014|15/07/2014|Standard Class|  EB-13705|        Ed Braxton|  Corporate|      Hamilton|             Waikato|    New Zealand|      null|  APAC|       Oceania| TEC-MA-10000858|     Technology|    Machines|   Panasonic Printer|      White|   529.8|       2|       0|       68.82|        39.87|\n",
      "|48870|   PL-2014-6080|14/11/2014|18/11/2014|Standard Class|   FM-4290|      Frank Merwin|Home Office|         Radom|             Masovia|         Poland|      null|  EMEA|          EMEA|FUR-OFF-10004495|      Furniture|      Chairs|Office Star Swive...|      Black|  171.51|       1|       0|       58.29|       17.65 |\n",
      "+-----+---------------+----------+----------+--------------+----------+------------------+-----------+--------------+--------------------+---------------+----------+------+--------------+----------------+---------------+------------+--------------------+-----------+--------+--------+--------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_coalescedf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd611519",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdf.createOrReplaceTempView('sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7e52756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |    sales|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ee81732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+------+\n",
      "|  country|            state|profit|\n",
      "+---------+-----------------+------+\n",
      "|Australia|  New South Wales|   0.1|\n",
      "|Australia|       Queensland|   0.1|\n",
      "|Australia|  New South Wales|   0.1|\n",
      "|Australia|       Queensland|   0.1|\n",
      "|Australia|       Queensland|   0.1|\n",
      "|Australia|       Queensland|   0.1|\n",
      "|Australia|Western Australia|   0.1|\n",
      "|Australia|         Victoria|   0.1|\n",
      "|Australia|  New South Wales|   0.1|\n",
      "|Australia|  New South Wales|     0|\n",
      "|Australia|  New South Wales|   0.1|\n",
      "|Australia|Western Australia|   0.1|\n",
      "|Australia|       Queensland|   0.1|\n",
      "|Australia|  New South Wales|   0.1|\n",
      "|Australia|  South Australia|   0.1|\n",
      "|Australia|  South Australia|   0.1|\n",
      "|Australia|Western Australia|   0.1|\n",
      "|Australia|       Queensland|   0.1|\n",
      "|Australia|Western Australia|   0.1|\n",
      "|Australia|  South Australia|   0.1|\n",
      "+---------+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+------------------+\n",
      "|    country|       sum(profit)|\n",
      "+-----------+------------------+\n",
      "|       Chad|               0.0|\n",
      "|     Russia|               0.0|\n",
      "|   Paraguay|             0.002|\n",
      "|      Yemen|20.999999999999996|\n",
      "|    Senegal|               0.0|\n",
      "|     Sweden|103.10000000000001|\n",
      "|Philippines|            235.55|\n",
      "|    Eritrea|               0.0|\n",
      "|   Djibouti|               0.0|\n",
      "|   Malaysia|               0.0|\n",
      "|  Singapore|               0.0|\n",
      "|     Turkey| 826.8000000000085|\n",
      "|       Iraq|               0.0|\n",
      "|    Germany| 117.7999999999997|\n",
      "|Afghanistan|               0.0|\n",
      "|   Cambodia|               0.0|\n",
      "|     Rwanda|               0.0|\n",
      "|     Jordan|               0.0|\n",
      "|      Sudan|               0.0|\n",
      "|     France|204.34999999999903|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select country , state, profit from sales where country='Australia'\").show()\n",
    "\n",
    "spark.sql(\"select country , sum(profit) from sales group by country\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a938b013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database shellida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db9c7dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "| shellida|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b049eeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use shellida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fcbc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63deefeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SparkRuntimeException",
     "evalue": "[LOCATION_ALREADY_EXISTS] Cannot name the managed table as `spark_catalog`.`shellida`.`sales_permanent`, as its associated location 'file:/home/labuser/spark-warehouse/shellida.db/sales_permanent' already exists. Please pick a different table name, or remove the existing location first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSparkRuntimeException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m salesdf\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39msaveAsTable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshellida.sales_permanent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/sql/readwriter.py:1521\u001b[0m, in \u001b[0;36mDataFrameWriter.saveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m-> 1521\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msaveAsTable(name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mSparkRuntimeException\u001b[0m: [LOCATION_ALREADY_EXISTS] Cannot name the managed table as `spark_catalog`.`shellida`.`sales_permanent`, as its associated location 'file:/home/labuser/spark-warehouse/shellida.db/sales_permanent' already exists. Please pick a different table name, or remove the existing location first."
     ]
    }
   ],
   "source": [
    "salesdf.write.saveAsTable(\"shellida.sales_permanent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f15aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |    sales|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59e8e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empdf = spark.read.csv(\"/home/labuser/Downloads/retail-main/datasets/emp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7097a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|_c0|_c1| _c2|\n",
      "+---+---+----+\n",
      "|111|zzz|8000|\n",
      "|111|aaa|8888|\n",
      "|121|bbb|8000|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69b97c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|    CustomerName|    Segment|         City|          State|      Country|PostalCode|Market|      Region|       ProductID|       Category|Sub-Category|         ProductName|           Sales|Quantity|Discount|    Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|32298| CA-2012-124891|31/07/2012|31/07/2012|      Same Day|  RH-19495|     Rick Hansen|   Consumer|New York City|       New York|United States|     10024|    US|        East| TEC-AC-10003033|     Technology| Accessories|Plantronics CS510...|         2309.65|       7|       0|  762.1845|     933.57 |     Critical|\n",
      "|26341|  IN-2013-77878|05/02/2013|07/02/2013|  Second Class|  JR-16210|   Justin Ritter|  Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|     Oceania| FUR-CH-10003950|      Furniture|      Chairs|Novimex Executive...|           Black|3709.395|       9|       0.1|    -288.765|      923.63 |\n",
      "|25330|  IN-2013-71249|17/10/2013|18/10/2013|   First Class|  CR-12730|    Craig Reiter|   Consumer|     Brisbane|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-PH-10004664|     Technology|      Phones|   Nokia Smart Phone|  with Caller ID|5175.171|       9|       0.1|     919.971|      915.49 |\n",
      "|13524|ES-2013-1579342|28/01/2013|30/01/2013|   First Class|  KM-16375|Katherine Murray|Home Office|       Berlin|         Berlin|      Germany|      null|    EU|     Central| TEC-PH-10004583|     Technology|      Phones|Motorola Smart Phone|        Cordless| 2892.51|       5|       0.1|      -96.54|      910.16 |\n",
      "|47221|   SG-2013-4320|05/11/2013|06/11/2013|      Same Day|   RH-9495|     Rick Hansen|   Consumer|        Dakar|          Dakar|      Senegal|      null|Africa|      Africa|TEC-SHA-10000501|     Technology|     Copiers|  Sharp Wireless Fax|      High-Speed| 2832.96|       8|         0|      311.52|      903.04 |\n",
      "|22732|  IN-2013-42360|28/06/2013|01/07/2013|  Second Class|  JM-15655|     Jim Mitchum|  Corporate|       Sydney|New South Wales|    Australia|      null|  APAC|     Oceania| TEC-PH-10000030|     Technology|      Phones| Samsung Smart Phone|  with Caller ID|2862.675|       5|       0.1|     763.275|      897.35 |\n",
      "|30570|  IN-2011-81826|07/11/2011|09/11/2011|   First Class|  TS-21340|   Toby Swindell|   Consumer|      Porirua|     Wellington|  New Zealand|      null|  APAC|     Oceania| FUR-CH-10004050|      Furniture|      Chairs|Novimex Executive...|      Adjustable| 1822.08|       4|         0|      564.84|       894.77|\n",
      "|31192|  IN-2012-86369|14/04/2012|18/04/2012|Standard Class|  MB-18085|      Mick Brown|   Consumer|     Hamilton|        Waikato|  New Zealand|      null|  APAC|     Oceania| FUR-TA-10002958|      Furniture|      Tables|Chromcraft Confer...| Fully Assembled| 5244.84|       6|         0|      996.48|       878.38|\n",
      "|40155| CA-2014-135909|14/10/2014|21/10/2014|Standard Class|  JW-15220|       Jane Waco|  Corporate|   Sacramento|     California|United States|     95823|    US|        West| OFF-BI-10003527|Office Supplies|     Binders|Fellowes PB500 El...|         5083.96|       5|     0.2|  1906.485|     867.69 |          Low|\n",
      "|40936| CA-2012-116638|28/01/2012|31/01/2012|  Second Class|  JH-15985|     Joseph Holt|   Consumer|      Concord| North Carolina|United States|     28027|    US|       South| FUR-TA-10000198|      Furniture|      Tables|Chromcraft Bull-N...|        4297.644|      13|     0.4|-1862.3124|     865.74 |     Critical|\n",
      "|34577| CA-2011-102988|05/04/2011|09/04/2011|  Second Class|  GM-14695|    Greg Maxwell|  Corporate|   Alexandria|       Virginia|United States|     22304|    US|       South| OFF-SU-10002881|Office Supplies|    Supplies|Martin Yale Chadl...|         4164.05|       5|       0|    83.281|     846.54 |         High|\n",
      "|28879|  ID-2012-28402|19/04/2012|22/04/2012|   First Class|  AJ-10780|  Anthony Jacobs|  Corporate|        Kabul|          Kabul|  Afghanistan|      null|  APAC|Central Asia| FUR-TA-10001889|      Furniture|      Tables|Bevis Conference ...| Fully Assembled| 4626.15|       5|         0|      647.55|      835.57 |\n",
      "|45794|   SA-2011-1830|27/12/2011|29/12/2011|  Second Class|   MM-7260| Magdelene Morse|   Consumer|        Jizan|          Jizan| Saudi Arabia|      null|  EMEA|        EMEA|TEC-CIS-10001717|     Technology|      Phones|   Cisco Smart Phone|  with Caller ID| 2616.96|       4|         0|      1151.4|      832.41 |\n",
      "| 4132| MX-2012-130015|13/11/2012|13/11/2012|      Same Day|  VF-21715|  Vicky Freymann|Home Office|       Toledo|         Parana|       Brazil|      null| LATAM|       South| FUR-CH-10002033|      Furniture|      Chairs|Harbour Creations...|      Adjustable|  2221.8|       7|         0|      622.02|      810.25 |\n",
      "|27704|  IN-2013-73951|06/06/2013|08/06/2013|  Second Class|  PF-19120|    Peter Fuller|   Consumer|   Mudanjiang|   Heilongjiang|        China|      null|  APAC|  North Asia| OFF-AP-10003500|Office Supplies|  Appliances|KitchenAid Microwave|           White| 3701.52|      12|         0|     1036.08|      804.54 |\n",
      "|13779|ES-2014-5099955|31/07/2014|03/08/2014|  Second Class|  BP-11185|    Ben Peterman|  Corporate|        Paris|  Ile-de-France|       France|      null|    EU|     Central| OFF-AP-10000423|Office Supplies|  Appliances|Breville Refriger...|             Red|1869.588|       4|       0.1|     186.948|      801.66 |\n",
      "|36178| CA-2014-143567|03/11/2014|06/11/2014|  Second Class|  TB-21175|   Thomas Boland|  Corporate|    Henderson|       Kentucky|United States|     42420|    US|       South| TEC-AC-10004145|     Technology| Accessories|Logitech diNovo E...|         2249.91|       9|       0|  517.4793|     780.70 |     Critical|\n",
      "|12069|ES-2014-1651774|08/09/2014|14/09/2014|Standard Class|  PJ-18835|   Patrick Jones|  Corporate|        Prato|        Tuscany|        Italy|      null|    EU|       South| OFF-AP-10004512|Office Supplies|  Appliances|        Hoover Stove|             Red| 7958.58|      14|         0|     3979.08|      778.32 |\n",
      "|22096|  IN-2014-11763|31/01/2014|01/02/2014|   First Class|  JS-15685|        Jim Sink|  Corporate|   Townsville|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-CO-10000865|     Technology|     Copiers| Brother Fax Machine|      High-Speed|2565.594|       9|       0.1|      28.404|      766.93 |\n",
      "|49463|   TZ-2014-8190|05/12/2014|07/12/2014|  Second Class|   RH-9555| Ritsa Hightower|   Consumer|       Uvinza|         Kigoma|     Tanzania|      null|Africa|      Africa|OFF-KIT-10004058|Office Supplies|  Appliances|    KitchenAid Stove|           White| 3409.74|       6|         0|      818.28|      763.38 |\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81d8689e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, OrderID: string, OrderDate: string, ShipDate: string, ShipMode: string, CustomerID: string, CustomerName: string, Segment: string, City: string, State: string, Country: string, PostalCode: string, Market: string, Region: string, ProductID: string, Category: string, Sub-Category: string, ProductName: string, Sales: string, Quantity: string, Discount: string, Profit: string, ShippingCost: string, OrderPriority: string]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06ff45db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51290"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "868a430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|_c0|_c1| _c2|\n",
      "+---+---+----+\n",
      "|111|zzz|8000|\n",
      "|111|aaa|8888|\n",
      "|121|bbb|8000|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07806aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|    CustomerName|    Segment|         City|          State|      Country|PostalCode|Market|      Region|       ProductID|       Category|Sub-Category|         ProductName|           Sales|Quantity|Discount|    Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|32298| CA-2012-124891|31/07/2012|31/07/2012|      Same Day|  RH-19495|     Rick Hansen|   Consumer|New York City|       New York|United States|     10024|    US|        East| TEC-AC-10003033|     Technology| Accessories|Plantronics CS510...|         2309.65|       7|       0|  762.1845|     933.57 |     Critical|\n",
      "|26341|  IN-2013-77878|05/02/2013|07/02/2013|  Second Class|  JR-16210|   Justin Ritter|  Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|     Oceania| FUR-CH-10003950|      Furniture|      Chairs|Novimex Executive...|           Black|3709.395|       9|       0.1|    -288.765|      923.63 |\n",
      "|25330|  IN-2013-71249|17/10/2013|18/10/2013|   First Class|  CR-12730|    Craig Reiter|   Consumer|     Brisbane|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-PH-10004664|     Technology|      Phones|   Nokia Smart Phone|  with Caller ID|5175.171|       9|       0.1|     919.971|      915.49 |\n",
      "|13524|ES-2013-1579342|28/01/2013|30/01/2013|   First Class|  KM-16375|Katherine Murray|Home Office|       Berlin|         Berlin|      Germany|      null|    EU|     Central| TEC-PH-10004583|     Technology|      Phones|Motorola Smart Phone|        Cordless| 2892.51|       5|       0.1|      -96.54|      910.16 |\n",
      "|47221|   SG-2013-4320|05/11/2013|06/11/2013|      Same Day|   RH-9495|     Rick Hansen|   Consumer|        Dakar|          Dakar|      Senegal|      null|Africa|      Africa|TEC-SHA-10000501|     Technology|     Copiers|  Sharp Wireless Fax|      High-Speed| 2832.96|       8|         0|      311.52|      903.04 |\n",
      "|22732|  IN-2013-42360|28/06/2013|01/07/2013|  Second Class|  JM-15655|     Jim Mitchum|  Corporate|       Sydney|New South Wales|    Australia|      null|  APAC|     Oceania| TEC-PH-10000030|     Technology|      Phones| Samsung Smart Phone|  with Caller ID|2862.675|       5|       0.1|     763.275|      897.35 |\n",
      "|30570|  IN-2011-81826|07/11/2011|09/11/2011|   First Class|  TS-21340|   Toby Swindell|   Consumer|      Porirua|     Wellington|  New Zealand|      null|  APAC|     Oceania| FUR-CH-10004050|      Furniture|      Chairs|Novimex Executive...|      Adjustable| 1822.08|       4|         0|      564.84|       894.77|\n",
      "|31192|  IN-2012-86369|14/04/2012|18/04/2012|Standard Class|  MB-18085|      Mick Brown|   Consumer|     Hamilton|        Waikato|  New Zealand|      null|  APAC|     Oceania| FUR-TA-10002958|      Furniture|      Tables|Chromcraft Confer...| Fully Assembled| 5244.84|       6|         0|      996.48|       878.38|\n",
      "|40155| CA-2014-135909|14/10/2014|21/10/2014|Standard Class|  JW-15220|       Jane Waco|  Corporate|   Sacramento|     California|United States|     95823|    US|        West| OFF-BI-10003527|Office Supplies|     Binders|Fellowes PB500 El...|         5083.96|       5|     0.2|  1906.485|     867.69 |          Low|\n",
      "|40936| CA-2012-116638|28/01/2012|31/01/2012|  Second Class|  JH-15985|     Joseph Holt|   Consumer|      Concord| North Carolina|United States|     28027|    US|       South| FUR-TA-10000198|      Furniture|      Tables|Chromcraft Bull-N...|        4297.644|      13|     0.4|-1862.3124|     865.74 |     Critical|\n",
      "|34577| CA-2011-102988|05/04/2011|09/04/2011|  Second Class|  GM-14695|    Greg Maxwell|  Corporate|   Alexandria|       Virginia|United States|     22304|    US|       South| OFF-SU-10002881|Office Supplies|    Supplies|Martin Yale Chadl...|         4164.05|       5|       0|    83.281|     846.54 |         High|\n",
      "|28879|  ID-2012-28402|19/04/2012|22/04/2012|   First Class|  AJ-10780|  Anthony Jacobs|  Corporate|        Kabul|          Kabul|  Afghanistan|      null|  APAC|Central Asia| FUR-TA-10001889|      Furniture|      Tables|Bevis Conference ...| Fully Assembled| 4626.15|       5|         0|      647.55|      835.57 |\n",
      "|45794|   SA-2011-1830|27/12/2011|29/12/2011|  Second Class|   MM-7260| Magdelene Morse|   Consumer|        Jizan|          Jizan| Saudi Arabia|      null|  EMEA|        EMEA|TEC-CIS-10001717|     Technology|      Phones|   Cisco Smart Phone|  with Caller ID| 2616.96|       4|         0|      1151.4|      832.41 |\n",
      "| 4132| MX-2012-130015|13/11/2012|13/11/2012|      Same Day|  VF-21715|  Vicky Freymann|Home Office|       Toledo|         Parana|       Brazil|      null| LATAM|       South| FUR-CH-10002033|      Furniture|      Chairs|Harbour Creations...|      Adjustable|  2221.8|       7|         0|      622.02|      810.25 |\n",
      "|27704|  IN-2013-73951|06/06/2013|08/06/2013|  Second Class|  PF-19120|    Peter Fuller|   Consumer|   Mudanjiang|   Heilongjiang|        China|      null|  APAC|  North Asia| OFF-AP-10003500|Office Supplies|  Appliances|KitchenAid Microwave|           White| 3701.52|      12|         0|     1036.08|      804.54 |\n",
      "|13779|ES-2014-5099955|31/07/2014|03/08/2014|  Second Class|  BP-11185|    Ben Peterman|  Corporate|        Paris|  Ile-de-France|       France|      null|    EU|     Central| OFF-AP-10000423|Office Supplies|  Appliances|Breville Refriger...|             Red|1869.588|       4|       0.1|     186.948|      801.66 |\n",
      "|36178| CA-2014-143567|03/11/2014|06/11/2014|  Second Class|  TB-21175|   Thomas Boland|  Corporate|    Henderson|       Kentucky|United States|     42420|    US|       South| TEC-AC-10004145|     Technology| Accessories|Logitech diNovo E...|         2249.91|       9|       0|  517.4793|     780.70 |     Critical|\n",
      "|12069|ES-2014-1651774|08/09/2014|14/09/2014|Standard Class|  PJ-18835|   Patrick Jones|  Corporate|        Prato|        Tuscany|        Italy|      null|    EU|       South| OFF-AP-10004512|Office Supplies|  Appliances|        Hoover Stove|             Red| 7958.58|      14|         0|     3979.08|      778.32 |\n",
      "|22096|  IN-2014-11763|31/01/2014|01/02/2014|   First Class|  JS-15685|        Jim Sink|  Corporate|   Townsville|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-CO-10000865|     Technology|     Copiers| Brother Fax Machine|      High-Speed|2565.594|       9|       0.1|      28.404|      766.93 |\n",
      "|49463|   TZ-2014-8190|05/12/2014|07/12/2014|  Second Class|   RH-9555| Ritsa Hightower|   Consumer|       Uvinza|         Kigoma|     Tanzania|      null|Africa|      Africa|OFF-KIT-10004058|Office Supplies|  Appliances|    KitchenAid Stove|           White| 3409.74|       6|         0|      818.28|      763.38 |\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5bb7d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, OrderID: string, OrderDate: string, ShipDate: string, ShipMode: string, CustomerID: string, CustomerName: string, Segment: string, City: string, State: string, Country: string, PostalCode: string, Market: string, Region: string, ProductID: string, Category: string, Sub-Category: string, ProductName: string, Sales: string, Quantity: string, Discount: string, Profit: string, ShippingCost: string, OrderPriority: string]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bc942bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, OrderID: string, OrderDate: string, ShipDate: string, ShipMode: string, CustomerID: string, CustomerName: string, Segment: string, City: string, State: string, Country: string, PostalCode: string, Market: string, Region: string, ProductID: string, Category: string, Sub-Category: string, ProductName: string, Sales: string, Quantity: string, Discount: string, Profit: string, ShippingCost: string, OrderPriority: string]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f760620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|    CustomerName|    Segment|         City|          State|      Country|PostalCode|Market|      Region|       ProductID|       Category|Sub-Category|         ProductName|           Sales|Quantity|Discount|    Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|32298| CA-2012-124891|31/07/2012|31/07/2012|      Same Day|  RH-19495|     Rick Hansen|   Consumer|New York City|       New York|United States|     10024|    US|        East| TEC-AC-10003033|     Technology| Accessories|Plantronics CS510...|         2309.65|       7|       0|  762.1845|     933.57 |     Critical|\n",
      "|26341|  IN-2013-77878|05/02/2013|07/02/2013|  Second Class|  JR-16210|   Justin Ritter|  Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|     Oceania| FUR-CH-10003950|      Furniture|      Chairs|Novimex Executive...|           Black|3709.395|       9|       0.1|    -288.765|      923.63 |\n",
      "|25330|  IN-2013-71249|17/10/2013|18/10/2013|   First Class|  CR-12730|    Craig Reiter|   Consumer|     Brisbane|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-PH-10004664|     Technology|      Phones|   Nokia Smart Phone|  with Caller ID|5175.171|       9|       0.1|     919.971|      915.49 |\n",
      "|13524|ES-2013-1579342|28/01/2013|30/01/2013|   First Class|  KM-16375|Katherine Murray|Home Office|       Berlin|         Berlin|      Germany|      null|    EU|     Central| TEC-PH-10004583|     Technology|      Phones|Motorola Smart Phone|        Cordless| 2892.51|       5|       0.1|      -96.54|      910.16 |\n",
      "|47221|   SG-2013-4320|05/11/2013|06/11/2013|      Same Day|   RH-9495|     Rick Hansen|   Consumer|        Dakar|          Dakar|      Senegal|      null|Africa|      Africa|TEC-SHA-10000501|     Technology|     Copiers|  Sharp Wireless Fax|      High-Speed| 2832.96|       8|         0|      311.52|      903.04 |\n",
      "|22732|  IN-2013-42360|28/06/2013|01/07/2013|  Second Class|  JM-15655|     Jim Mitchum|  Corporate|       Sydney|New South Wales|    Australia|      null|  APAC|     Oceania| TEC-PH-10000030|     Technology|      Phones| Samsung Smart Phone|  with Caller ID|2862.675|       5|       0.1|     763.275|      897.35 |\n",
      "|30570|  IN-2011-81826|07/11/2011|09/11/2011|   First Class|  TS-21340|   Toby Swindell|   Consumer|      Porirua|     Wellington|  New Zealand|      null|  APAC|     Oceania| FUR-CH-10004050|      Furniture|      Chairs|Novimex Executive...|      Adjustable| 1822.08|       4|         0|      564.84|       894.77|\n",
      "|31192|  IN-2012-86369|14/04/2012|18/04/2012|Standard Class|  MB-18085|      Mick Brown|   Consumer|     Hamilton|        Waikato|  New Zealand|      null|  APAC|     Oceania| FUR-TA-10002958|      Furniture|      Tables|Chromcraft Confer...| Fully Assembled| 5244.84|       6|         0|      996.48|       878.38|\n",
      "|40155| CA-2014-135909|14/10/2014|21/10/2014|Standard Class|  JW-15220|       Jane Waco|  Corporate|   Sacramento|     California|United States|     95823|    US|        West| OFF-BI-10003527|Office Supplies|     Binders|Fellowes PB500 El...|         5083.96|       5|     0.2|  1906.485|     867.69 |          Low|\n",
      "|40936| CA-2012-116638|28/01/2012|31/01/2012|  Second Class|  JH-15985|     Joseph Holt|   Consumer|      Concord| North Carolina|United States|     28027|    US|       South| FUR-TA-10000198|      Furniture|      Tables|Chromcraft Bull-N...|        4297.644|      13|     0.4|-1862.3124|     865.74 |     Critical|\n",
      "|34577| CA-2011-102988|05/04/2011|09/04/2011|  Second Class|  GM-14695|    Greg Maxwell|  Corporate|   Alexandria|       Virginia|United States|     22304|    US|       South| OFF-SU-10002881|Office Supplies|    Supplies|Martin Yale Chadl...|         4164.05|       5|       0|    83.281|     846.54 |         High|\n",
      "|28879|  ID-2012-28402|19/04/2012|22/04/2012|   First Class|  AJ-10780|  Anthony Jacobs|  Corporate|        Kabul|          Kabul|  Afghanistan|      null|  APAC|Central Asia| FUR-TA-10001889|      Furniture|      Tables|Bevis Conference ...| Fully Assembled| 4626.15|       5|         0|      647.55|      835.57 |\n",
      "|45794|   SA-2011-1830|27/12/2011|29/12/2011|  Second Class|   MM-7260| Magdelene Morse|   Consumer|        Jizan|          Jizan| Saudi Arabia|      null|  EMEA|        EMEA|TEC-CIS-10001717|     Technology|      Phones|   Cisco Smart Phone|  with Caller ID| 2616.96|       4|         0|      1151.4|      832.41 |\n",
      "| 4132| MX-2012-130015|13/11/2012|13/11/2012|      Same Day|  VF-21715|  Vicky Freymann|Home Office|       Toledo|         Parana|       Brazil|      null| LATAM|       South| FUR-CH-10002033|      Furniture|      Chairs|Harbour Creations...|      Adjustable|  2221.8|       7|         0|      622.02|      810.25 |\n",
      "|27704|  IN-2013-73951|06/06/2013|08/06/2013|  Second Class|  PF-19120|    Peter Fuller|   Consumer|   Mudanjiang|   Heilongjiang|        China|      null|  APAC|  North Asia| OFF-AP-10003500|Office Supplies|  Appliances|KitchenAid Microwave|           White| 3701.52|      12|         0|     1036.08|      804.54 |\n",
      "|13779|ES-2014-5099955|31/07/2014|03/08/2014|  Second Class|  BP-11185|    Ben Peterman|  Corporate|        Paris|  Ile-de-France|       France|      null|    EU|     Central| OFF-AP-10000423|Office Supplies|  Appliances|Breville Refriger...|             Red|1869.588|       4|       0.1|     186.948|      801.66 |\n",
      "|36178| CA-2014-143567|03/11/2014|06/11/2014|  Second Class|  TB-21175|   Thomas Boland|  Corporate|    Henderson|       Kentucky|United States|     42420|    US|       South| TEC-AC-10004145|     Technology| Accessories|Logitech diNovo E...|         2249.91|       9|       0|  517.4793|     780.70 |     Critical|\n",
      "|12069|ES-2014-1651774|08/09/2014|14/09/2014|Standard Class|  PJ-18835|   Patrick Jones|  Corporate|        Prato|        Tuscany|        Italy|      null|    EU|       South| OFF-AP-10004512|Office Supplies|  Appliances|        Hoover Stove|             Red| 7958.58|      14|         0|     3979.08|      778.32 |\n",
      "|22096|  IN-2014-11763|31/01/2014|01/02/2014|   First Class|  JS-15685|        Jim Sink|  Corporate|   Townsville|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-CO-10000865|     Technology|     Copiers| Brother Fax Machine|      High-Speed|2565.594|       9|       0.1|      28.404|      766.93 |\n",
      "|49463|   TZ-2014-8190|05/12/2014|07/12/2014|  Second Class|   RH-9555| Ritsa Hightower|   Consumer|       Uvinza|         Kigoma|     Tanzania|      null|Africa|      Africa|OFF-KIT-10004058|Office Supplies|  Appliances|    KitchenAid Stove|           White| 3409.74|       6|         0|      818.28|      763.38 |\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salesdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c511d258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51290"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c3f721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|    CustomerName|    Segment|         City|          State|      Country|PostalCode|Market|      Region|       ProductID|       Category|Sub-Category|         ProductName|           Sales|Quantity|Discount|    Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|32298| CA-2012-124891|31/07/2012|31/07/2012|      Same Day|  RH-19495|     Rick Hansen|   Consumer|New York City|       New York|United States|     10024|    US|        East| TEC-AC-10003033|     Technology| Accessories|Plantronics CS510...|         2309.65|       7|       0|  762.1845|     933.57 |     Critical|\n",
      "|26341|  IN-2013-77878|05/02/2013|07/02/2013|  Second Class|  JR-16210|   Justin Ritter|  Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|     Oceania| FUR-CH-10003950|      Furniture|      Chairs|Novimex Executive...|           Black|3709.395|       9|       0.1|    -288.765|      923.63 |\n",
      "|25330|  IN-2013-71249|17/10/2013|18/10/2013|   First Class|  CR-12730|    Craig Reiter|   Consumer|     Brisbane|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-PH-10004664|     Technology|      Phones|   Nokia Smart Phone|  with Caller ID|5175.171|       9|       0.1|     919.971|      915.49 |\n",
      "|13524|ES-2013-1579342|28/01/2013|30/01/2013|   First Class|  KM-16375|Katherine Murray|Home Office|       Berlin|         Berlin|      Germany|      null|    EU|     Central| TEC-PH-10004583|     Technology|      Phones|Motorola Smart Phone|        Cordless| 2892.51|       5|       0.1|      -96.54|      910.16 |\n",
      "|47221|   SG-2013-4320|05/11/2013|06/11/2013|      Same Day|   RH-9495|     Rick Hansen|   Consumer|        Dakar|          Dakar|      Senegal|      null|Africa|      Africa|TEC-SHA-10000501|     Technology|     Copiers|  Sharp Wireless Fax|      High-Speed| 2832.96|       8|         0|      311.52|      903.04 |\n",
      "|22732|  IN-2013-42360|28/06/2013|01/07/2013|  Second Class|  JM-15655|     Jim Mitchum|  Corporate|       Sydney|New South Wales|    Australia|      null|  APAC|     Oceania| TEC-PH-10000030|     Technology|      Phones| Samsung Smart Phone|  with Caller ID|2862.675|       5|       0.1|     763.275|      897.35 |\n",
      "|30570|  IN-2011-81826|07/11/2011|09/11/2011|   First Class|  TS-21340|   Toby Swindell|   Consumer|      Porirua|     Wellington|  New Zealand|      null|  APAC|     Oceania| FUR-CH-10004050|      Furniture|      Chairs|Novimex Executive...|      Adjustable| 1822.08|       4|         0|      564.84|       894.77|\n",
      "|31192|  IN-2012-86369|14/04/2012|18/04/2012|Standard Class|  MB-18085|      Mick Brown|   Consumer|     Hamilton|        Waikato|  New Zealand|      null|  APAC|     Oceania| FUR-TA-10002958|      Furniture|      Tables|Chromcraft Confer...| Fully Assembled| 5244.84|       6|         0|      996.48|       878.38|\n",
      "|40155| CA-2014-135909|14/10/2014|21/10/2014|Standard Class|  JW-15220|       Jane Waco|  Corporate|   Sacramento|     California|United States|     95823|    US|        West| OFF-BI-10003527|Office Supplies|     Binders|Fellowes PB500 El...|         5083.96|       5|     0.2|  1906.485|     867.69 |          Low|\n",
      "|40936| CA-2012-116638|28/01/2012|31/01/2012|  Second Class|  JH-15985|     Joseph Holt|   Consumer|      Concord| North Carolina|United States|     28027|    US|       South| FUR-TA-10000198|      Furniture|      Tables|Chromcraft Bull-N...|        4297.644|      13|     0.4|-1862.3124|     865.74 |     Critical|\n",
      "|34577| CA-2011-102988|05/04/2011|09/04/2011|  Second Class|  GM-14695|    Greg Maxwell|  Corporate|   Alexandria|       Virginia|United States|     22304|    US|       South| OFF-SU-10002881|Office Supplies|    Supplies|Martin Yale Chadl...|         4164.05|       5|       0|    83.281|     846.54 |         High|\n",
      "|28879|  ID-2012-28402|19/04/2012|22/04/2012|   First Class|  AJ-10780|  Anthony Jacobs|  Corporate|        Kabul|          Kabul|  Afghanistan|      null|  APAC|Central Asia| FUR-TA-10001889|      Furniture|      Tables|Bevis Conference ...| Fully Assembled| 4626.15|       5|         0|      647.55|      835.57 |\n",
      "|45794|   SA-2011-1830|27/12/2011|29/12/2011|  Second Class|   MM-7260| Magdelene Morse|   Consumer|        Jizan|          Jizan| Saudi Arabia|      null|  EMEA|        EMEA|TEC-CIS-10001717|     Technology|      Phones|   Cisco Smart Phone|  with Caller ID| 2616.96|       4|         0|      1151.4|      832.41 |\n",
      "| 4132| MX-2012-130015|13/11/2012|13/11/2012|      Same Day|  VF-21715|  Vicky Freymann|Home Office|       Toledo|         Parana|       Brazil|      null| LATAM|       South| FUR-CH-10002033|      Furniture|      Chairs|Harbour Creations...|      Adjustable|  2221.8|       7|         0|      622.02|      810.25 |\n",
      "|27704|  IN-2013-73951|06/06/2013|08/06/2013|  Second Class|  PF-19120|    Peter Fuller|   Consumer|   Mudanjiang|   Heilongjiang|        China|      null|  APAC|  North Asia| OFF-AP-10003500|Office Supplies|  Appliances|KitchenAid Microwave|           White| 3701.52|      12|         0|     1036.08|      804.54 |\n",
      "|13779|ES-2014-5099955|31/07/2014|03/08/2014|  Second Class|  BP-11185|    Ben Peterman|  Corporate|        Paris|  Ile-de-France|       France|      null|    EU|     Central| OFF-AP-10000423|Office Supplies|  Appliances|Breville Refriger...|             Red|1869.588|       4|       0.1|     186.948|      801.66 |\n",
      "|36178| CA-2014-143567|03/11/2014|06/11/2014|  Second Class|  TB-21175|   Thomas Boland|  Corporate|    Henderson|       Kentucky|United States|     42420|    US|       South| TEC-AC-10004145|     Technology| Accessories|Logitech diNovo E...|         2249.91|       9|       0|  517.4793|     780.70 |     Critical|\n",
      "|12069|ES-2014-1651774|08/09/2014|14/09/2014|Standard Class|  PJ-18835|   Patrick Jones|  Corporate|        Prato|        Tuscany|        Italy|      null|    EU|       South| OFF-AP-10004512|Office Supplies|  Appliances|        Hoover Stove|             Red| 7958.58|      14|         0|     3979.08|      778.32 |\n",
      "|22096|  IN-2014-11763|31/01/2014|01/02/2014|   First Class|  JS-15685|        Jim Sink|  Corporate|   Townsville|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-CO-10000865|     Technology|     Copiers| Brother Fax Machine|      High-Speed|2565.594|       9|       0.1|      28.404|      766.93 |\n",
      "|49463|   TZ-2014-8190|05/12/2014|07/12/2014|  Second Class|   RH-9555| Ritsa Hightower|   Consumer|       Uvinza|         Kigoma|     Tanzania|      null|Africa|      Africa|OFF-KIT-10004058|Office Supplies|  Appliances|    KitchenAid Stove|           White| 3409.74|       6|         0|      818.28|      763.38 |\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3016d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e219e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, OrderID: string, OrderDate: string, ShipDate: string, ShipMode: string, CustomerID: string, CustomerName: string, Segment: string, City: string, State: string, Country: string, PostalCode: string, Market: string, Region: string, ProductID: string, Category: string, Sub-Category: string, ProductName: string, Sales: string, Quantity: string, Discount: string, Profit: string, ShippingCost: string, OrderPriority: string]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b314a943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, OrderID: string, OrderDate: string, ShipDate: string, ShipMode: string, CustomerID: string, CustomerName: string, Segment: string, City: string, State: string, Country: string, PostalCode: string, Market: string, Region: string, ProductID: string, Category: string, Sub-Category: string, ProductName: string, Sales: string, Quantity: string, Discount: string, Profit: string, ShippingCost: string, OrderPriority: string]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.persist(StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31806d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 63:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+----------+----------+------------+----------+-------------+---------+-------------+---------------+-------------+----------+------+-------+---------------+----------+------------+--------------------+-------+--------+--------+--------+------------+-------------+\n",
      "|   ID|       OrderID| OrderDate|  ShipDate|    ShipMode|CustomerID| CustomerName|  Segment|         City|          State|      Country|PostalCode|Market| Region|      ProductID|  Category|Sub-Category|         ProductName|  Sales|Quantity|Discount|  Profit|ShippingCost|OrderPriority|\n",
      "+-----+--------------+----------+----------+------------+----------+-------------+---------+-------------+---------------+-------------+----------+------+-------+---------------+----------+------------+--------------------+-------+--------+--------+--------+------------+-------------+\n",
      "|32298|CA-2012-124891|31/07/2012|31/07/2012|    Same Day|  RH-19495|  Rick Hansen| Consumer|New York City|       New York|United States|     10024|    US|   East|TEC-AC-10003033|Technology| Accessories|Plantronics CS510...|2309.65|       7|       0|762.1845|     933.57 |     Critical|\n",
      "|26341| IN-2013-77878|05/02/2013|07/02/2013|Second Class|  JR-16210|Justin Ritter|Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|Oceania|FUR-CH-10003950| Furniture|      Chairs|Novimex Executive...|  Black|3709.395|       9|     0.1|    -288.765|      923.63 |\n",
      "+-----+--------------+----------+----------+------------+----------+-------------+---------+-------------+---------------+-------------+----------+------+-------+---------------+----------+------------+--------------------+-------+--------+--------+--------+------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/25 04:31:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "23/09/25 04:31:54 WARN BlockManager: Block rdd_229_0 replicated to only 0 peer(s) instead of 1 peers\n",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salesdf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de9c9826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, OrderID: string, OrderDate: string, ShipDate: string, ShipMode: string, CustomerID: string, CustomerName: string, Segment: string, City: string, State: string, Country: string, PostalCode: string, Market: string, Region: string, ProductID: string, Category: string, Sub-Category: string, ProductName: string, Sales: string, Quantity: string, Discount: string, Profit: string, ShippingCost: string, OrderPriority: string]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "532c62f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, OrderID: string, OrderDate: string, ShipDate: string, ShipMode: string, CustomerID: string, CustomerName: string, Segment: string, City: string, State: string, Country: string, PostalCode: string, Market: string, Region: string, ProductID: string, Category: string, Sub-Category: string, ProductName: string, Sales: string, Quantity: string, Discount: string, Profit: string, ShippingCost: string, OrderPriority: string]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e227cb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left semi join\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+----+-------+------+------+\n",
      "|Emp_id| Empname|MGR| YOJ|dept_id|gender|salary|\n",
      "+------+--------+---+----+-------+------+------+\n",
      "|     1|   Smith|  1|2018|     10|     M|3000.0|\n",
      "|     3|Williams|  1|2010|     10|     M|1000.0|\n",
      "|     4|   Jones|  2|2005|     10|     F|2000.0|\n",
      "|     2|    Rose|  1|2010|     20|     M|4000.0|\n",
      "|     5|   Brown|  2|2010|     40|      | 300.0|\n",
      "+------+--------+---+----+-------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Smith\",1,\"2018\",\"10\",\"M\",3000.00), \n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000.00), \n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000.00), \n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000.00), \n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",300.00), \n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",2000.00) \n",
    "  ]\n",
    "\n",
    "EmpSchema = StructType([  \n",
    "    StructField('Emp_id', IntegerType(), True), \n",
    "    StructField('Empname', StringType(), True),\n",
    "    StructField('MGR', IntegerType(), True), \n",
    "   StructField('YOJ', StringType(), True), \n",
    "     StructField('dept_id', StringType(), True), \n",
    "    StructField('gender', StringType(), True), \n",
    "     StructField('salary', DoubleType(), True) \n",
    "])\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = EmpSchema)\n",
    "\n",
    "\n",
    "dept = [(\"Finance\",10), \n",
    "    (\"Marketing\",20), \n",
    "    (\"Sales\",30), \n",
    "    (\"IT\",40) \n",
    "  ]\n",
    "\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "\n",
    "\n",
    "print(\"left semi join\")\n",
    "leftsemidf = empDF.join(deptDF,empDF.dept_id ==  deptDF.dept_id,\"leftsemi\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3af13df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftsemidf = empDF.join(deptDF,empDF.dept_id ==  deptDF.dept_id,\"leftsemi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ec158e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 70:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---+----+-------+------+------+\n",
      "|Emp_id|Empname|MGR| YOJ|dept_id|gender|salary|\n",
      "+------+-------+---+----+-------+------+------+\n",
      "|     6|  Brown|  2|2010|     50|      |2000.0|\n",
      "+------+-------+---+----+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.dept_id ==  deptDF.dept_id,\"leftanti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8ccd856",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftantidf = empDF.join(deptDF,empDF.dept_id ==  deptDF.dept_id,\"leftanti\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfd4631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joindfdf = empDF.join(deptDF,leftsemidf.dept_id ==  leftantidf.dept_id,\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce6bce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 76:===================>                                      (1 + 2) / 3]\r",
      "\r",
      "[Stage 76:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+----+-------+------+------+---------+-------+\n",
      "|Emp_id| Empname|MGR| YOJ|dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---+----+-------+------+------+---------+-------+\n",
      "|     1|   Smith|  1|2018|     10|     M|3000.0|  Finance|     10|\n",
      "|     1|   Smith|  1|2018|     10|     M|3000.0|Marketing|     20|\n",
      "|     2|    Rose|  1|2010|     20|     M|4000.0|  Finance|     10|\n",
      "|     2|    Rose|  1|2010|     20|     M|4000.0|Marketing|     20|\n",
      "|     3|Williams|  1|2010|     10|     M|1000.0|  Finance|     10|\n",
      "|     3|Williams|  1|2010|     10|     M|1000.0|Marketing|     20|\n",
      "|     1|   Smith|  1|2018|     10|     M|3000.0|    Sales|     30|\n",
      "|     1|   Smith|  1|2018|     10|     M|3000.0|       IT|     40|\n",
      "|     2|    Rose|  1|2010|     20|     M|4000.0|    Sales|     30|\n",
      "|     2|    Rose|  1|2010|     20|     M|4000.0|       IT|     40|\n",
      "|     3|Williams|  1|2010|     10|     M|1000.0|    Sales|     30|\n",
      "|     3|Williams|  1|2010|     10|     M|1000.0|       IT|     40|\n",
      "|     4|   Jones|  2|2005|     10|     F|2000.0|  Finance|     10|\n",
      "|     4|   Jones|  2|2005|     10|     F|2000.0|Marketing|     20|\n",
      "|     5|   Brown|  2|2010|     40|      | 300.0|  Finance|     10|\n",
      "|     5|   Brown|  2|2010|     40|      | 300.0|Marketing|     20|\n",
      "|     6|   Brown|  2|2010|     50|      |2000.0|  Finance|     10|\n",
      "|     6|   Brown|  2|2010|     50|      |2000.0|Marketing|     20|\n",
      "|     4|   Jones|  2|2005|     10|     F|2000.0|    Sales|     30|\n",
      "|     4|   Jones|  2|2005|     10|     F|2000.0|       IT|     40|\n",
      "+------+--------+---+----+-------+------+------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joindfdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c144bf04",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m empDF[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdept_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdept_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdept_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "empDF[\"dept_name\", \"dept_id\", sum(\"salary\")].sort(\"dept_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "empDF.select(col(\"salary\").cast(\"int\"))\n",
    "\n",
    "# col(\"salary\").cast(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa203b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "empDF.select(type(\"salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c907909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77a84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d656a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d69c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d92d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdf = spark.createDataFrame(data=emp, schema = EmpSchema)\n",
    "sales_US =salesdf.groupBy(\"Country\",\"Category\").agg(sum(\"Profit\").alias(\"totSales\")).filter(\"country='India'\").show()\n",
    "\n",
    "salesdf.select(\"Region\").where(\"Country='India'\").orderBy(\"region\",ascending=True).show()\n",
    "salesdf.select(\"Region\").where(\"Country='India'\").orderBy(\"region\",ascending=False).show()\n",
    "\n",
    "salesdf.select(\"Region\").where(\"Country='India'\").sort(salesDF.region.desc().show())\n",
    "\n",
    "spark.sql(\"select country,region,avg(profit) from sales group by country,region\").filter(\"Country='India'\").orderBy(\"region\").show()\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "salesDF.select(\"Region\").where(\"Country='India'\").sort(col(\"region\")).show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef9a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9240bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e60f4df",
   "metadata": {},
   "source": [
    "25/09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show databases\").show()\n",
    "\n",
    "spark.sql(\"use shellida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4cb8f1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create table employee(empno int, ename string,sal int);\n",
    "\n",
    "# desc extended employee;\n",
    "\n",
    "\n",
    "salesdf=spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/home/labuser/Downloads/retail-main/datasets/superstore.csv\")\n",
    "\n",
    "salesdf.write.mode(\"overwrite\").saveAsTable(\"sale\")\n",
    "\n",
    "sales4tabledf= spark.read.table(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07c9b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesdf = spark.read.table(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b38e64bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 77:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|   ID|        OrderID| OrderDate|  ShipDate|      ShipMode|CustomerID|    CustomerName|    Segment|         City|          State|      Country|PostalCode|Market|      Region|       ProductID|       Category|Sub-Category|         ProductName|           Sales|Quantity|Discount|    Profit|ShippingCost|OrderPriority|\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "|32298| CA-2012-124891|31/07/2012|31/07/2012|      Same Day|  RH-19495|     Rick Hansen|   Consumer|New York City|       New York|United States|     10024|    US|        East| TEC-AC-10003033|     Technology| Accessories|Plantronics CS510...|         2309.65|       7|       0|  762.1845|     933.57 |     Critical|\n",
      "|26341|  IN-2013-77878|05/02/2013|07/02/2013|  Second Class|  JR-16210|   Justin Ritter|  Corporate|   Wollongong|New South Wales|    Australia|      null|  APAC|     Oceania| FUR-CH-10003950|      Furniture|      Chairs|Novimex Executive...|           Black|3709.395|       9|       0.1|    -288.765|      923.63 |\n",
      "|25330|  IN-2013-71249|17/10/2013|18/10/2013|   First Class|  CR-12730|    Craig Reiter|   Consumer|     Brisbane|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-PH-10004664|     Technology|      Phones|   Nokia Smart Phone|  with Caller ID|5175.171|       9|       0.1|     919.971|      915.49 |\n",
      "|13524|ES-2013-1579342|28/01/2013|30/01/2013|   First Class|  KM-16375|Katherine Murray|Home Office|       Berlin|         Berlin|      Germany|      null|    EU|     Central| TEC-PH-10004583|     Technology|      Phones|Motorola Smart Phone|        Cordless| 2892.51|       5|       0.1|      -96.54|      910.16 |\n",
      "|47221|   SG-2013-4320|05/11/2013|06/11/2013|      Same Day|   RH-9495|     Rick Hansen|   Consumer|        Dakar|          Dakar|      Senegal|      null|Africa|      Africa|TEC-SHA-10000501|     Technology|     Copiers|  Sharp Wireless Fax|      High-Speed| 2832.96|       8|         0|      311.52|      903.04 |\n",
      "|22732|  IN-2013-42360|28/06/2013|01/07/2013|  Second Class|  JM-15655|     Jim Mitchum|  Corporate|       Sydney|New South Wales|    Australia|      null|  APAC|     Oceania| TEC-PH-10000030|     Technology|      Phones| Samsung Smart Phone|  with Caller ID|2862.675|       5|       0.1|     763.275|      897.35 |\n",
      "|30570|  IN-2011-81826|07/11/2011|09/11/2011|   First Class|  TS-21340|   Toby Swindell|   Consumer|      Porirua|     Wellington|  New Zealand|      null|  APAC|     Oceania| FUR-CH-10004050|      Furniture|      Chairs|Novimex Executive...|      Adjustable| 1822.08|       4|         0|      564.84|       894.77|\n",
      "|31192|  IN-2012-86369|14/04/2012|18/04/2012|Standard Class|  MB-18085|      Mick Brown|   Consumer|     Hamilton|        Waikato|  New Zealand|      null|  APAC|     Oceania| FUR-TA-10002958|      Furniture|      Tables|Chromcraft Confer...| Fully Assembled| 5244.84|       6|         0|      996.48|       878.38|\n",
      "|40155| CA-2014-135909|14/10/2014|21/10/2014|Standard Class|  JW-15220|       Jane Waco|  Corporate|   Sacramento|     California|United States|     95823|    US|        West| OFF-BI-10003527|Office Supplies|     Binders|Fellowes PB500 El...|         5083.96|       5|     0.2|  1906.485|     867.69 |          Low|\n",
      "|40936| CA-2012-116638|28/01/2012|31/01/2012|  Second Class|  JH-15985|     Joseph Holt|   Consumer|      Concord| North Carolina|United States|     28027|    US|       South| FUR-TA-10000198|      Furniture|      Tables|Chromcraft Bull-N...|        4297.644|      13|     0.4|-1862.3124|     865.74 |     Critical|\n",
      "|34577| CA-2011-102988|05/04/2011|09/04/2011|  Second Class|  GM-14695|    Greg Maxwell|  Corporate|   Alexandria|       Virginia|United States|     22304|    US|       South| OFF-SU-10002881|Office Supplies|    Supplies|Martin Yale Chadl...|         4164.05|       5|       0|    83.281|     846.54 |         High|\n",
      "|28879|  ID-2012-28402|19/04/2012|22/04/2012|   First Class|  AJ-10780|  Anthony Jacobs|  Corporate|        Kabul|          Kabul|  Afghanistan|      null|  APAC|Central Asia| FUR-TA-10001889|      Furniture|      Tables|Bevis Conference ...| Fully Assembled| 4626.15|       5|         0|      647.55|      835.57 |\n",
      "|45794|   SA-2011-1830|27/12/2011|29/12/2011|  Second Class|   MM-7260| Magdelene Morse|   Consumer|        Jizan|          Jizan| Saudi Arabia|      null|  EMEA|        EMEA|TEC-CIS-10001717|     Technology|      Phones|   Cisco Smart Phone|  with Caller ID| 2616.96|       4|         0|      1151.4|      832.41 |\n",
      "| 4132| MX-2012-130015|13/11/2012|13/11/2012|      Same Day|  VF-21715|  Vicky Freymann|Home Office|       Toledo|         Parana|       Brazil|      null| LATAM|       South| FUR-CH-10002033|      Furniture|      Chairs|Harbour Creations...|      Adjustable|  2221.8|       7|         0|      622.02|      810.25 |\n",
      "|27704|  IN-2013-73951|06/06/2013|08/06/2013|  Second Class|  PF-19120|    Peter Fuller|   Consumer|   Mudanjiang|   Heilongjiang|        China|      null|  APAC|  North Asia| OFF-AP-10003500|Office Supplies|  Appliances|KitchenAid Microwave|           White| 3701.52|      12|         0|     1036.08|      804.54 |\n",
      "|13779|ES-2014-5099955|31/07/2014|03/08/2014|  Second Class|  BP-11185|    Ben Peterman|  Corporate|        Paris|  Ile-de-France|       France|      null|    EU|     Central| OFF-AP-10000423|Office Supplies|  Appliances|Breville Refriger...|             Red|1869.588|       4|       0.1|     186.948|      801.66 |\n",
      "|36178| CA-2014-143567|03/11/2014|06/11/2014|  Second Class|  TB-21175|   Thomas Boland|  Corporate|    Henderson|       Kentucky|United States|     42420|    US|       South| TEC-AC-10004145|     Technology| Accessories|Logitech diNovo E...|         2249.91|       9|       0|  517.4793|     780.70 |     Critical|\n",
      "|12069|ES-2014-1651774|08/09/2014|14/09/2014|Standard Class|  PJ-18835|   Patrick Jones|  Corporate|        Prato|        Tuscany|        Italy|      null|    EU|       South| OFF-AP-10004512|Office Supplies|  Appliances|        Hoover Stove|             Red| 7958.58|      14|         0|     3979.08|      778.32 |\n",
      "|22096|  IN-2014-11763|31/01/2014|01/02/2014|   First Class|  JS-15685|        Jim Sink|  Corporate|   Townsville|     Queensland|    Australia|      null|  APAC|     Oceania| TEC-CO-10000865|     Technology|     Copiers| Brother Fax Machine|      High-Speed|2565.594|       9|       0.1|      28.404|      766.93 |\n",
      "|49463|   TZ-2014-8190|05/12/2014|07/12/2014|  Second Class|   RH-9555| Ritsa Hightower|   Consumer|       Uvinza|         Kigoma|     Tanzania|      null|Africa|      Africa|OFF-KIT-10004058|Office Supplies|  Appliances|    KitchenAid Stove|           White| 3409.74|       6|         0|      818.28|      763.38 |\n",
      "+-----+---------------+----------+----------+--------------+----------+----------------+-----------+-------------+---------------+-------------+----------+------+------------+----------------+---------------+------------+--------------------+----------------+--------+--------+----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salesdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f4fdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales4tabledf=spark.read.table(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "25d5972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "salesdf.write.mode(\"append\").saveAsTable(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6e94e3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0873f2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51290"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "90bd8200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+----------+\n",
      "|      country|         state|    Profit|\n",
      "+-------------+--------------+----------+\n",
      "|United States|      New York|  762.1845|\n",
      "|United States|    California|  1906.485|\n",
      "|United States|North Carolina|-1862.3124|\n",
      "|United States|      Virginia|    83.281|\n",
      "|United States|      Kentucky|  517.4793|\n",
      "|United States|      Illinois|   341.994|\n",
      "|United States|    California|  363.9048|\n",
      "|United States|         Texas|   -350.49|\n",
      "|United States|    California|  135.4068|\n",
      "|United States|      New York| 1371.9804|\n",
      "|United States|North Carolina|-3839.9904|\n",
      "|United States|     Minnesota| 4630.4755|\n",
      "|United States|      New York|  1143.891|\n",
      "|United States|    California|   839.986|\n",
      "|United States|    Washington| 1480.4671|\n",
      "|United States|       Florida|  327.5922|\n",
      "|United States|      New York|  2229.024|\n",
      "|United States|      Virginia|  694.5015|\n",
      "|United States|       Georgia|  3177.475|\n",
      "|United States|      Michigan| 2504.2216|\n",
      "+-------------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesUS = salesdf.select(\"country\",\"state\",\"Profit\").filter(\"country='United States'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ba19066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country: string, region: string, avg(profit): double]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum,avg\n",
    "\n",
    "sales_US =salesdf.groupBy(\"Country\",\"state\").agg(sum(col(\"Profit\").cast('int')).alias(\"totSales\"),avg(col(\"Profit\").cast('int')).alias(\"AvgSales\")).filter(\"country='United States'\")\n",
    "salesdf.select(\"Region\",\"country\").sort(col(\"region\").desc()).orderBy(\"country\",ascending=False).filter(\"region='Central Asia'\").distinct()\n",
    "\n",
    "spark.sql(\"select country,region,avg(profit) from sales group by country,region\").filter(\"Country='India'\").orderBy(\"region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4d429586",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_US=sales_US.withColumn(\"CountryCode\", lit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "34b60df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Country: string, state: string, totSales: bigint, AvgSales: double, CountryCode: string]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "sales_US.withColumn(\"CountryCode\",lit(\"US\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "43273a86",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.withColumn() missing 1 required positional argument: 'col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sales_withcolumn \u001b[38;5;241m=\u001b[39m salesdf\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesLevel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwhen(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwhen(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m10000\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: DataFrame.withColumn() missing 1 required positional argument: 'col'"
     ]
    }
   ],
   "source": [
    "sales_withcolumn = salesdf.withColumn(\"SalesLevel\").when(col(\"profit\")>=10000,\"High\").when(col(\"profit\")<10000,\"Average\").otherwise(\"NA\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261e7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d86535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
